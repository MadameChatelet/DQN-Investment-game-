{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque \n",
    "#special kind of list for the memory of our agent\n",
    "#deque is like a list where you can add things from the top or end of the list\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential # BUILD OUR NURAL NETWORK\n",
    "#to aproximate optimal Q\n",
    "from tensorflow.keras.layers import Dense#we will just use dense layers\n",
    "from tensorflow.keras.optimizers import Adam#as optimizer we will use Adam, estoCASTIC GRADIENT DESCENT\n",
    "import os #to create directories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. define environment\n",
    "\n",
    "#we have 4 different state\n",
    "#and 4 different actions\n",
    "\n",
    "state_size = 4\n",
    "action_size = 5\n",
    "batch_size = 32 #for our gradient descent, hyperparameter you can vary for powers of two\n",
    "\n",
    "n_episodes = 1001#number of games we want our agent to play\n",
    "#number of games we play, provides as with more data for training\n",
    "#in each of this episodes, we are gonna randomly remember,\n",
    "#some of the things that happen in that episode\n",
    "#we are gonna use that memory to train de RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_SUS_ID\"#to run it in our cpu\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "output_dir = 'model_output/cartpole'# define a directory, to store model output\n",
    "\n",
    "#this code if to not allow to create the directory if alreadt exists\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle\n",
    "\n",
    "class Corona():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "\n",
    "\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.debt, self.spending = -2000, 6000\n",
    "        \n",
    "\n",
    "        #Background\n",
    "        self.win = turtle.Screen() #create screen\n",
    "        self.win.title('After Corona World') \n",
    "        self.win.bgcolor('green')\n",
    "        self.win.tracer(0)\n",
    "        self.win.setup(width = 600, height = 600)\n",
    "\n",
    "        #house\n",
    "        self.house = turtle.Turtle()\n",
    "        self.house.shape('square')\n",
    "        self.house.speed(0)\n",
    "        self.house.shapesize(stretch_wid=3, stretch_len=3)   # Streach the length of square by 5 \n",
    "        self.house.penup()\n",
    "        self.house.color('white')       # Set the color to white\n",
    "        self.house.goto(0, 0) \n",
    "        self.roof = turtle.Turtle()\n",
    "        self.roof.shape('triangle')\n",
    "        self.roof.tilt(-30)\n",
    "        self.roof.speed(0)\n",
    "        self.roof.shapesize(stretch_wid=3, stretch_len=3)   # Streach the length of square by 5 \n",
    "        self.roof.penup()\n",
    "        self.roof.color('red')       # Set the color to white\n",
    "        self.roof.goto(0, 50-3) \n",
    "\n",
    "        #cinema\n",
    "        self.super1 = turtle.Turtle()\n",
    "        self.super1.shape('square')\n",
    "        self.super1.speed(0)\n",
    "        self.super1.shapesize(stretch_wid=2.5, stretch_len=4)   # Streach the length of square by 5 \n",
    "        self.super1.penup()\n",
    "        self.super1.color('brown')       # Set the color to white\n",
    "        self.super1.goto( 160 , 0) \n",
    "\n",
    "\n",
    "        #PIZZERIA\n",
    "        self.super2 = turtle.Turtle()\n",
    "        self.super2.shape('square')\n",
    "        self.super2.speed(0)\n",
    "        self.super2.shapesize(stretch_wid=2.5, stretch_len=4)   # Streach the length of square by 5 \n",
    "        self.super2.penup()\n",
    "        self.super2.color('yellow')       # Set the color to white\n",
    "        self.super2.goto( -160, 0 ) \n",
    "\n",
    "        #super3\n",
    "        self.super3 = turtle.Turtle()\n",
    "        self.super3.shape('square')\n",
    "        self.super3.speed(0)\n",
    "        self.super3.shapesize(stretch_wid=2.5, stretch_len=4)   # Streach the length of square by 5 \n",
    "        self.super3.penup()\n",
    "        self.super3.color('orange')       # Set the color to white\n",
    "        self.super3.goto( 0, -160) \n",
    "\n",
    "        #cinema\n",
    "        self.park = turtle.Turtle()\n",
    "        self.park.shape('circle')\n",
    "        self.park.speed(0)\n",
    "        self.park.shapesize(stretch_wid=3.5, stretch_len=6)   # Streach the length of square by 5 \n",
    "        self.park.penup()\n",
    "        self.park.color('blue')       # Set the color to white\n",
    "        self.park.goto( 0, 160)\n",
    "        \n",
    "      \n",
    "\n",
    "        # Bilbo Beggins\n",
    "        self.bilbo = turtle.Turtle()      # Create a turtle object\n",
    "        self.bilbo.speed(0)\n",
    "        self.bilbo.shape('circle')        # Select a circle shape\n",
    "        self.bilbo.color('violet')           # Set the color to red\n",
    "        self.bilbo.penup()\n",
    "        self.bilbo.goto(0, 0)           # Place the shape in middle\n",
    "\n",
    "        #names\n",
    "        self.name = turtle.Turtle()\n",
    "        self.name.speed(0)\n",
    "        self.name.color('black')\n",
    "        self.name.penup()\n",
    "        self.name.hideturtle()\n",
    "        \n",
    "        #CINEMA\n",
    "        self.name.goto(110,150)\n",
    "        self.name.write(\"D: +20\\n$: -8\", align='center', font=('Courier', 14, 'normal'))\n",
    "        self.name.goto(0,200)\n",
    "        self.name.write(\"CINEMA\", align='center', font=('Courier', 14, 'normal'))\n",
    "        \n",
    "        #PIZZERIA\n",
    "        self.name.goto(160+70,-10)\n",
    "        self.name.write(\"D: +1\\n$: -20\", align='center', font=('Courier', 14, 'normal'))\n",
    "        self.name.goto(160, 30)\n",
    "        self.name.write(\"PIZZERIA\", align='center', font=('Courier', 14, 'normal'))        \n",
    "\n",
    "        #COFFE SHOP\n",
    "        self.name.goto(-160-70,-10)\n",
    "        self.name.write(\"D: +6\\n$: -5\", align='center', font=('Courier', 14, 'normal'))\n",
    "        self.name.goto(-160, 30)\n",
    "        self.name.write(\"COFFE SHOP\", align='center', font=('Courier', 14, 'normal')) \n",
    "        \n",
    "        #SUPERMARKET\n",
    "        self.name.goto(70,-170)\n",
    "        self.name.write(\"D: +2\\n$: -100\", align='center', font=('Courier', 14, 'normal'))\n",
    "        self.name.goto(0,-160+30)\n",
    "        self.name.write(\"SUPERMARKET\", align='center', font=('Courier', 14, 'normal')) \n",
    "        \n",
    "        #Scorecard\n",
    "        self.score = turtle.Turtle()\n",
    "        self.score.speed(0)\n",
    "        self.score.color('black')\n",
    "        self.score.penup()\n",
    "        self.score.hideturtle()\n",
    "        self.score.goto(0,250)\n",
    "        self.score.write(\"Debt: {}  Savings: {}\".format(self.debt, self.spending), align='center', font=('Courier', 24, 'normal'))\n",
    "\n",
    "\n",
    "\n",
    "    def bilbo_cinema(self):\n",
    "         self.bilbo.goto(0,160)    \n",
    "\n",
    "    def bilbo_pizzeria(self):\n",
    "        self.bilbo.goto(160,0)\n",
    "\n",
    "    def bilbo_supermarket(self):\n",
    "        self.bilbo.goto(0,-160)    \n",
    "\n",
    "    def bilbo_coffe(self):\n",
    "        self.bilbo.goto(-160, 0)    \n",
    "            \n",
    "    def bilbo_home(self):\n",
    "        self.bilbo.goto(0, 0) \n",
    "\n",
    "# -------------RL----------\n",
    "    #ACTIONS              | REWARDS > 4000 (incentivize spend  | REWARDS < 4000((incentivize save)  \n",
    "    #  0 go to cinema        ->    +2                           ->   +1  \n",
    "    #  1 go to pizzeria      ->    +2                           ->   +1\n",
    "    #  2 go to supermarket   ->    +1                           ->   +3\n",
    "    #  3 go to coffe shop    ->    +1                           ->   +2\n",
    "    #  4 go home=do nothing  ->    0                            ->   +2\n",
    "    \n",
    "    def reset(self):\n",
    "        self.bilbo.goto(0,0)\n",
    "        return [self.bilbo.xcor()*0.01, self.bilbo.ycor()*0.01, self.spending, self.debt]\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.done = 0\n",
    "        \n",
    "        if action == 0:\n",
    "            self.bilbo_cinema()\n",
    "            self.reward -= .1\n",
    "            \n",
    "        if action == 1:\n",
    "            self.bilbo_pizzeria()\n",
    "            self.reward -= .1\n",
    "            \n",
    "        if action == 2:\n",
    "            self.bilbo_supermarket()\n",
    "            self.reward -= .1\n",
    "            \n",
    "        if action == 3:\n",
    "            self.bilbo_coffe()\n",
    "            self.reward -= .1  \n",
    "            \n",
    "        if action == 4:\n",
    "            self.bilbo_home()\n",
    "            self.reward -= .1  \n",
    "            \n",
    "            \n",
    "            \n",
    "        self.run_frame()\n",
    "        \n",
    "        state = [self.bilbo.xcor()*0.01, self.bilbo.ycor()*0.01, self.spending, self.debt]#, self.people, self.spending]\n",
    "        \n",
    "        #maybe put people and spendings for each supermarket?\n",
    "        \n",
    "        return self.reward, state, self.done\n",
    "    \n",
    "    \n",
    "    def run_frame(self):\n",
    "        \n",
    "      \n",
    "    \n",
    "        self.win.update()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.bilbo.pos() == (0, 160):#if Bilbo goes to the cinema\n",
    "                    self.bilbo.sety(160-1)\n",
    "                    self.reward += 2 *((self.spending/6000)+(-2000/(self.debt+0.00000001)))\n",
    "                    self.debt += 20\n",
    "                    self.spending -= 8\n",
    "                    self.score.clear()\n",
    "                    self.score.write(\"Debt: {}  Savings: {}\".format(self.debt, self.spending), align='center', font=('Courier', 24, 'normal'))\n",
    "\n",
    "\n",
    "\n",
    "        if self.bilbo.pos() == (160, 0):#if Bilbo goes to the pizzeria\n",
    "                self.bilbo.setx(160-1)     \n",
    "                self.reward += 3*((self.spending/6000)+(-2000/(self.debt+0.00000001))) #because he buys grosseies\n",
    "                self.debt += 1\n",
    "                self.spending -= 20\n",
    "                self.score.clear()\n",
    "                self.score.write(\"Debt: {}  Savings: {}\".format(self.debt, self.spending), align='center', font=('Courier', 24, 'normal'))\n",
    "\n",
    "\n",
    "        if self.bilbo.pos() == (0, -160):#if Bilbo goes to the Supermarket 2\n",
    "                self.bilbo.sety(-160+1)\n",
    "                self.reward += 2*((self.spending/6000)+(-2000/(self.debt+0.00000001)))#because he buys grosseies\n",
    "                self.debt += 2\n",
    "                self.spending -= 100\n",
    "                self.score.clear()\n",
    "                self.score.write(\"Debt: {}  Savings: {}\".format(self.debt, self.spending), align='center', font=('Courier', 24, 'normal'))\n",
    "\n",
    "        if self.bilbo.pos() == (-160, 0):#if Bilbo goes to the coffe shop\n",
    "                self.bilbo.setx(-160+1)\n",
    "                self.reward += 2*((self.spending/6000)+(-2000/(self.debt+0.00000001)))#because he buys grosseies\n",
    "                self.debt += 6\n",
    "                self.spending -= 5\n",
    "                self.score.clear()\n",
    "                self.score.write(\"Debt: {}  Savings: {}\".format(self.debt, self.spending), align='center', font=('Courier', 24, 'normal'))\n",
    "\n",
    "\n",
    "        if self.bilbo.pos() == (0, 0):#if Bilbo goes home\n",
    "                self.bilbo.setx(+1)\n",
    "                self.reward += 1*((self.spending/6000)+(-2000/(self.debt+0.00000001))) #because people is 0\n",
    "                self.score.clear()\n",
    "                self.score.write(\"Debt: {}  Savings: {}\".format(self.debt, self.spending), align='center', font=('Courier', 24, 'normal'))\n",
    "   \n",
    "           \n",
    "\n",
    "        self.x = self.spending \n",
    "        self.y = self.debt \n",
    "        if self.spending <= 500 or self.debt > 0 :#or self.people >= 4000\n",
    "            self.done = True\n",
    "            self.spending = 6000 #savings\n",
    "            self.debt = -2000\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "    def end_frame(self):\n",
    "        \n",
    "        self.spending = 6000 #savings\n",
    "        self.debt = -2000\n",
    "        self.score.clear()\n",
    "        self.score.write(\"Debt: {}  Savings: {}\".format(self.debt, self.spending), align='center', font=('Courier', 24, 'normal'))\n",
    "\n",
    "       \n",
    "            \n",
    "    def spend(self, x):\n",
    "        \n",
    "        return int(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=2000) # double-ended queue; acts like list, but elements can be added/removed from either end\n",
    "        self.gamma = 0.95 # decay or discount rate: enables agent to take into account future actions in addition to the immediate ones, but discounted at this rate\n",
    "        self.epsilon = 1.0 # exploration rate: how much to act randomly; more initially than later due to epsilon decay\n",
    "        self.epsilon_decay = 0.995 # decrease number of random explorations as the agent's performance (hopefully) improves over time\n",
    "        self.epsilon_min = 0.01 # minimum amount of random exploration permitted\n",
    "        self.learning_rate = 0.001 # rate at which NN adjusts models parameters via SGD to reduce cost \n",
    "        self.model = self._build_model() # private method \n",
    "    \n",
    "    def _build_model(self):\n",
    "        # neural net to approximate Q-value function:\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu')) # 1st hidden layer; states as input\n",
    "        model.add(Dense(24, activation='relu')) # 2nd hidden layer\n",
    "        model.add(Dense(self.action_size, activation='linear')) # 2 actions, so 2 output neurons: 0 and 1 (L/R)\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done)) # list of previous experiences, enabling re-training later\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon: # if acting randomly, take random action\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state) # if not acting randomly, predict reward value based on current state\n",
    "        return np.argmax(act_values[0]) # pick the action that will give the highest reward (i.e., go left or right?)\n",
    "\n",
    "    def replay(self, batch_size): # method that trains NN with experiences sampled from memory\n",
    "        minibatch = random.sample(self.memory, batch_size) # sample a minibatch from memory\n",
    "        for state, action, reward, next_state, done in minibatch: # extract data for each minibatch sample\n",
    "            target = reward # if done (boolean whether game ended or not, i.e., whether final state or not), then target = reward\n",
    "            if not done: # if not done, then predict future discounted reward\n",
    "                target = (reward + self.gamma * # (target) = reward + (discount rate gamma) * \n",
    "                          np.amax(self.model.predict(next_state)[0])) # (maximum target Q based on future action a')\n",
    "            target_f = self.model.predict(state) # approximately map current state to future discounted reward\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0) # single epoch of training with x=state, y=target_f; fit decreases loss btwn target_f and y_hat\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interacting with an OPENAI gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(state_size, action_size) #initialize our agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interact with environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/1001, reward: 711.5, e: 1.0, savings: 2289, debt: -966,\n",
      "episode: 1/1001, reward: 725.7, e: 0.99, savings: 1090, debt: -866,\n",
      "episode: 2/1001, reward: 675.9, e: 0.99, savings: 802, debt: -1057,\n",
      "episode: 3/1001, reward: 715.4, e: 0.99, savings: 1251, debt: -838,\n",
      "episode: 4/1001, reward: 707.3, e: 0.98, savings: 1452, debt: -959,\n",
      "episode: 5/1001, reward: 695.6, e: 0.98, savings: 1086, debt: -1003,\n",
      "episode: 6/1001, reward: 720.6, e: 0.97, savings: 1376, debt: -893,\n",
      "episode: 7/1001, reward: 743.9, e: 0.97, savings: 1457, debt: -815,\n",
      "episode: 8/1001, reward: 662.6, e: 0.96, savings: 1345, debt: -1086,\n",
      "episode: 9/1001, reward: 610.3, e: 0.96, savings: 5256, debt: -1899,\n",
      "episode: 10/1001, reward: 766.1, e: 0.95, savings: 1924, debt: -784,\n",
      "episode: 11/1001, reward: 701.4, e: 0.95, savings: 1316, debt: -890,\n",
      "episode: 12/1001, reward: 818.5, e: 0.94, savings: 2144, debt: -803,\n",
      "episode: 13/1001, reward: 715.0, e: 0.94, savings: 5704, debt: -1952,\n",
      "episode: 14/1001, reward: 824.7, e: 0.93, savings: 1664, debt: -800,\n",
      "episode: 15/1001, reward: 655.7, e: 0.93, savings: 1022, debt: -993,\n",
      "episode: 16/1001, reward: 719.0, e: 0.92, savings: 958, debt: -830,\n",
      "episode: 17/1001, reward: 744.7, e: 0.92, savings: 1807, debt: -910,\n",
      "episode: 18/1001, reward: 744.4, e: 0.91, savings: 530, debt: -801,\n",
      "episode: 19/1001, reward: 732.4, e: 0.91, savings: 498, debt: -989,\n",
      "episode: 20/1001, reward: 743.9, e: 0.9, savings: 1891, debt: -783,\n",
      "episode: 21/1001, reward: 655.2, e: 0.9, savings: 606, debt: -1020,\n",
      "episode: 22/1001, reward: 706.1, e: 0.9, savings: 5857, debt: -1959,\n",
      "episode: 23/1001, reward: 753.9, e: 0.89, savings: 2130, debt: -882,\n",
      "episode: 24/1001, reward: 774.7, e: 0.89, savings: 2095, debt: -831,\n",
      "episode: 25/1001, reward: 627.3, e: 0.88, savings: 5147, debt: -1829,\n",
      "episode: 26/1001, reward: 642.6, e: 0.88, savings: 2115, debt: -1230,\n",
      "episode: 27/1001, reward: 767.3, e: 0.87, savings: 1638, debt: -765,\n",
      "episode: 28/1001, reward: 731.1, e: 0.87, savings: 1243, debt: -997,\n",
      "episode: 29/1001, reward: 694.4, e: 0.86, savings: 5975, debt: -1993,\n",
      "episode: 30/1001, reward: 630.0, e: 0.86, savings: 4312, debt: -1794,\n",
      "episode: 31/1001, reward: 743.6, e: 0.86, savings: 2028, debt: -954,\n",
      "episode: 32/1001, reward: 713.7, e: 0.85, savings: 1655, debt: -882,\n",
      "episode: 33/1001, reward: 780.8, e: 0.85, savings: 2183, debt: -827,\n",
      "episode: 34/1001, reward: 732.5, e: 0.84, savings: 2002, debt: -1009,\n",
      "episode: 35/1001, reward: 786.6, e: 0.84, savings: 2380, debt: -986,\n",
      "episode: 36/1001, reward: 749.0, e: 0.83, savings: 2187, debt: -955,\n",
      "episode: 37/1001, reward: 692.5, e: 0.83, savings: 1431, debt: -971,\n",
      "episode: 38/1001, reward: 678.5, e: 0.83, savings: 1722, debt: -1151,\n",
      "episode: 39/1001, reward: 736.5, e: 0.82, savings: 1961, debt: -979,\n",
      "episode: 40/1001, reward: 833.1, e: 0.82, savings: 1159, debt: -602,\n",
      "episode: 41/1001, reward: 696.4, e: 0.81, savings: 2100, debt: -1045,\n",
      "episode: 42/1001, reward: 662.2, e: 0.81, savings: 4790, debt: -1762,\n",
      "episode: 43/1001, reward: 734.7, e: 0.81, savings: 1156, debt: -614,\n",
      "episode: 44/1001, reward: 623.5, e: 0.8, savings: 1887, debt: -1073,\n",
      "episode: 45/1001, reward: 768.9, e: 0.8, savings: 1781, debt: -850,\n",
      "episode: 46/1001, reward: 651.7, e: 0.79, savings: 5323, debt: -1877,\n",
      "episode: 47/1001, reward: 705.6, e: 0.79, savings: 1700, debt: -997,\n",
      "episode: 48/1001, reward: 814.2, e: 0.79, savings: 1949, debt: -721,\n",
      "episode: 49/1001, reward: 816.0, e: 0.78, savings: 1959, debt: -802,\n",
      "episode: 50/1001, reward: 771.7, e: 0.78, savings: 2606, debt: -942,\n",
      "episode: 51/1001, reward: 869.9, e: 0.77, savings: 1615, debt: -548,\n",
      "episode: 52/1001, reward: 728.4, e: 0.77, savings: 2552, debt: -1111,\n",
      "episode: 53/1001, reward: 780.3, e: 0.77, savings: 2333, debt: -958,\n",
      "episode: 54/1001, reward: 760.6, e: 0.76, savings: 1902, debt: -727,\n",
      "episode: 55/1001, reward: 780.2, e: 0.76, savings: 2262, debt: -956,\n",
      "episode: 56/1001, reward: 823.8, e: 0.76, savings: 3121, debt: -754,\n",
      "episode: 57/1001, reward: 806.5, e: 0.75, savings: 2942, debt: -750,\n",
      "episode: 58/1001, reward: 582.5, e: 0.75, savings: 584, debt: -1174,\n",
      "episode: 59/1001, reward: 718.5, e: 0.74, savings: 2216, debt: -952,\n",
      "episode: 60/1001, reward: 574.9, e: 0.74, savings: 1407, debt: -1130,\n",
      "episode: 61/1001, reward: 774.4, e: 0.74, savings: 1954, debt: -897,\n",
      "episode: 62/1001, reward: 731.3, e: 0.73, savings: 1024, debt: -515,\n",
      "episode: 63/1001, reward: 647.3, e: 0.73, savings: 2206, debt: -1150,\n",
      "episode: 64/1001, reward: 757.0, e: 0.73, savings: 2491, debt: -876,\n",
      "episode: 65/1001, reward: 777.4, e: 0.72, savings: 2064, debt: -889,\n",
      "episode: 66/1001, reward: 728.1, e: 0.72, savings: 2263, debt: -949,\n",
      "episode: 67/1001, reward: 864.2, e: 0.71, savings: 1907, debt: -523,\n",
      "episode: 68/1001, reward: 619.2, e: 0.71, savings: 5335, debt: -1979,\n",
      "episode: 69/1001, reward: 756.4, e: 0.71, savings: 1752, debt: -1009,\n",
      "episode: 70/1001, reward: 530.3, e: 0.7, savings: 5670, debt: -1981,\n",
      "episode: 71/1001, reward: 752.6, e: 0.7, savings: 2202, debt: -1031,\n",
      "episode: 72/1001, reward: 906.8, e: 0.7, savings: 1390, debt: -425,\n",
      "episode: 73/1001, reward: 902.8, e: 0.69, savings: 1859, debt: -570,\n",
      "episode: 74/1001, reward: 870.1, e: 0.69, savings: 2167, debt: -751,\n",
      "episode: 75/1001, reward: 842.2, e: 0.69, savings: 2191, debt: -886,\n",
      "episode: 76/1001, reward: 578.6, e: 0.68, savings: 4494, debt: -1769,\n",
      "episode: 77/1001, reward: 915.1, e: 0.68, savings: 1921, debt: -674,\n",
      "episode: 78/1001, reward: 575.5, e: 0.68, savings: 2565, debt: -1264,\n",
      "episode: 79/1001, reward: 772.7, e: 0.67, savings: 2804, debt: -796,\n",
      "episode: 80/1001, reward: 586.4, e: 0.67, savings: 2017, debt: -1304,\n",
      "episode: 81/1001, reward: 701.6, e: 0.67, savings: 1981, debt: -1288,\n",
      "episode: 82/1001, reward: 854.8, e: 0.66, savings: 1976, debt: -671,\n",
      "episode: 83/1001, reward: 616.7, e: 0.66, savings: 2690, debt: -1697,\n",
      "episode: 84/1001, reward: 1.132e+03, e: 0.66, savings: 2359, debt: -467,\n",
      "episode: 85/1001, reward: 762.5, e: 0.65, savings: 2218, debt: -1343,\n",
      "episode: 86/1001, reward: 771.7, e: 0.65, savings: 1002, debt: -1040,\n",
      "episode: 87/1001, reward: 566.2, e: 0.65, savings: 3116, debt: -1232,\n",
      "episode: 88/1001, reward: 959.2, e: 0.64, savings: 1489, debt: -445,\n",
      "episode: 89/1001, reward: 760.9, e: 0.64, savings: 1825, debt: -1333,\n",
      "episode: 90/1001, reward: 783.3, e: 0.64, savings: 2917, debt: -916,\n",
      "episode: 91/1001, reward: 529.6, e: 0.63, savings: 3035, debt: -1365,\n",
      "episode: 92/1001, reward: 779.3, e: 0.63, savings: 3202, debt: -904,\n",
      "episode: 93/1001, reward: 1.007e+03, e: 0.63, savings: 2041, debt: -576,\n",
      "episode: 94/1001, reward: 938.9, e: 0.62, savings: 2729, debt: -636,\n",
      "episode: 95/1001, reward: 852.2, e: 0.62, savings: 2741, debt: -672,\n",
      "episode: 96/1001, reward: 1.055e+03, e: 0.62, savings: 999, debt: -286,\n",
      "episode: 97/1001, reward: 875.9, e: 0.61, savings: 1839, debt: -609,\n",
      "episode: 98/1001, reward: 1.046e+03, e: 0.61, savings: 5952, debt: -1978,\n",
      "episode: 99/1001, reward: 968.5, e: 0.61, savings: 504, debt: -233,\n",
      "episode: 100/1001, reward: 930.4, e: 0.61, savings: 2103, debt: -526,\n",
      "episode: 101/1001, reward: 894.7, e: 0.6, savings: 1969, debt: -673,\n",
      "episode: 102/1001, reward: 761.4, e: 0.6, savings: 3234, debt: -993,\n",
      "episode: 103/1001, reward: 832.1, e: 0.6, savings: 2362, debt: -956,\n",
      "episode: 104/1001, reward: 887.3, e: 0.59, savings: 2464, debt: -812,\n",
      "episode: 105/1001, reward: 846.5, e: 0.59, savings: 2268, debt: -713,\n",
      "episode: 106/1001, reward: 799.9, e: 0.59, savings: 2254, debt: -901,\n",
      "episode: 107/1001, reward: 837.5, e: 0.58, savings: 1095, debt: -399,\n",
      "episode: 108/1001, reward: 860.2, e: 0.58, savings: 2391, debt: -810,\n",
      "episode: 109/1001, reward: 863.9, e: 0.58, savings: 1465, debt: -578,\n",
      "episode: 110/1001, reward: 817.6, e: 0.58, savings: 2098, debt: -948,\n",
      "episode: 111/1001, reward: 763.5, e: 0.57, savings: 3495, debt: -1019,\n",
      "episode: 112/1001, reward: 870.3, e: 0.57, savings: 2171, debt: -781,\n",
      "episode: 113/1001, reward: 835.8, e: 0.57, savings: 1810, debt: -779,\n",
      "episode: 114/1001, reward: 758.2, e: 0.56, savings: 2225, debt: -1118,\n",
      "episode: 115/1001, reward: 865.6, e: 0.56, savings: 2435, debt: -844,\n",
      "episode: 116/1001, reward: 929.5, e: 0.56, savings: 520, debt: -290,\n",
      "episode: 117/1001, reward: 848.0, e: 0.56, savings: 2345, debt: -857,\n",
      "episode: 118/1001, reward: 816.1, e: 0.55, savings: 1821, debt: -738,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 119/1001, reward: 837.0, e: 0.55, savings: 2535, debt: -872,\n",
      "episode: 120/1001, reward: 744.8, e: 0.55, savings: 3386, debt: -978,\n",
      "episode: 121/1001, reward: 731.7, e: 0.55, savings: 3208, debt: -996,\n",
      "episode: 122/1001, reward: 852.5, e: 0.54, savings: 1154, debt: -521,\n",
      "episode: 123/1001, reward: 838.6, e: 0.54, savings: 2152, debt: -779,\n",
      "episode: 124/1001, reward: 750.5, e: 0.54, savings: 2091, debt: -1192,\n",
      "episode: 125/1001, reward: 819.4, e: 0.53, savings: 2746, debt: -956,\n",
      "episode: 126/1001, reward: 867.4, e: 0.53, savings: 2400, debt: -851,\n",
      "episode: 127/1001, reward: 887.6, e: 0.53, savings: 557, debt: -281,\n",
      "episode: 128/1001, reward: 757.8, e: 0.53, savings: 2302, debt: -1016,\n",
      "episode: 129/1001, reward: 846.7, e: 0.52, savings: 2357, debt: -806,\n",
      "episode: 130/1001, reward: 860.2, e: 0.52, savings: 2046, debt: -795,\n",
      "episode: 131/1001, reward: 910.9, e: 0.52, savings: 2029, debt: -661,\n",
      "episode: 132/1001, reward: 846.4, e: 0.52, savings: 1781, debt: -802,\n",
      "episode: 133/1001, reward: 813.4, e: 0.51, savings: 2292, debt: -807,\n",
      "episode: 134/1001, reward: 804.4, e: 0.51, savings: 3757, debt: -874,\n",
      "episode: 135/1001, reward: 855.2, e: 0.51, savings: 2412, debt: -924,\n",
      "episode: 136/1001, reward: 988.9, e: 0.51, savings: 2019, debt: -646,\n",
      "episode: 137/1001, reward: 1.024e+03, e: 0.5, savings: 542, debt: -260,\n",
      "episode: 138/1001, reward: 744.3, e: 0.5, savings: 3042, debt: -868,\n",
      "episode: 139/1001, reward: 818.4, e: 0.5, savings: 1859, debt: -840,\n",
      "episode: 140/1001, reward: 835.7, e: 0.5, savings: 2433, debt: -1013,\n",
      "episode: 141/1001, reward: 793.2, e: 0.49, savings: 2009, debt: -1115,\n",
      "episode: 142/1001, reward: 779.6, e: 0.49, savings: 3381, debt: -955,\n",
      "episode: 143/1001, reward: 796.1, e: 0.49, savings: 3469, debt: -964,\n",
      "episode: 144/1001, reward: 979.9, e: 0.49, savings: 1824, debt: -579,\n",
      "episode: 145/1001, reward: 609.5, e: 0.48, savings: 2851, debt: -1845,\n",
      "episode: 146/1001, reward: 799.3, e: 0.48, savings: 2235, debt: -910,\n",
      "episode: 147/1001, reward: 783.8, e: 0.48, savings: 5224, debt: -1920,\n",
      "episode: 148/1001, reward: 792.7, e: 0.48, savings: 3527, debt: -955,\n",
      "episode: 149/1001, reward: 618.7, e: 0.47, savings: 2417, debt: -1765,\n",
      "episode: 150/1001, reward: 748.4, e: 0.47, savings: 3381, debt: -1001,\n",
      "episode: 151/1001, reward: 914.0, e: 0.47, savings: 4790, debt: -1964,\n",
      "episode: 152/1001, reward: 807.7, e: 0.47, savings: 2146, debt: -1200,\n",
      "episode: 153/1001, reward: 1.151e+03, e: 0.46, savings: 534, debt: -168,\n",
      "episode: 154/1001, reward: 856.2, e: 0.46, savings: 1973, debt: -924,\n",
      "episode: 155/1001, reward: 887.8, e: 0.46, savings: 3115, debt: -660,\n",
      "episode: 156/1001, reward: 1.049e+03, e: 0.46, savings: 3042, debt: -793,\n",
      "episode: 157/1001, reward: 868.8, e: 0.46, savings: 3012, debt: -719,\n",
      "episode: 158/1001, reward: 892.2, e: 0.45, savings: 2645, debt: -880,\n",
      "episode: 159/1001, reward: 786.0, e: 0.45, savings: 3441, debt: -958,\n",
      "episode: 160/1001, reward: 884.3, e: 0.45, savings: 2755, debt: -986,\n",
      "episode: 161/1001, reward: 944.7, e: 0.45, savings: 5552, debt: -1970,\n",
      "episode: 162/1001, reward: 821.4, e: 0.44, savings: 2578, debt: -1432,\n",
      "episode: 163/1001, reward: 754.0, e: 0.44, savings: 3312, debt: -1054,\n",
      "episode: 164/1001, reward: 621.2, e: 0.44, savings: 2589, debt: -1451,\n",
      "episode: 165/1001, reward: 856.5, e: 0.44, savings: 2043, debt: -801,\n",
      "episode: 166/1001, reward: 858.3, e: 0.44, savings: 2331, debt: -1278,\n",
      "episode: 167/1001, reward: 1.028e+03, e: 0.43, savings: 5271, debt: -1920,\n",
      "episode: 168/1001, reward: 848.4, e: 0.43, savings: 2184, debt: -1322,\n",
      "episode: 169/1001, reward: 878.4, e: 0.43, savings: 1890, debt: -699,\n",
      "episode: 170/1001, reward: 746.1, e: 0.43, savings: 2610, debt: -953,\n",
      "episode: 171/1001, reward: 753.5, e: 0.42, savings: 5068, debt: -1864,\n",
      "episode: 172/1001, reward: 803.1, e: 0.42, savings: 2024, debt: -1208,\n",
      "episode: 173/1001, reward: 565.7, e: 0.42, savings: 5237, debt: -1946,\n",
      "episode: 174/1001, reward: 575.7, e: 0.42, savings: 4159, debt: -1242,\n",
      "episode: 175/1001, reward: 817.0, e: 0.42, savings: 3380, debt: -953,\n",
      "episode: 176/1001, reward: 780.8, e: 0.41, savings: 3118, debt: -1172,\n",
      "episode: 177/1001, reward: 673.6, e: 0.41, savings: 3526, debt: -1100,\n",
      "episode: 178/1001, reward: 937.9, e: 0.41, savings: 2382, debt: -764,\n",
      "episode: 179/1001, reward: 550.6, e: 0.41, savings: 637, debt: -1609,\n",
      "episode: 180/1001, reward: 473.9, e: 0.41, savings: 4157, debt: -1550,\n",
      "episode: 181/1001, reward: 3.474e+03, e: 0.4, savings: 2618, debt: -37,\n",
      "episode: 182/1001, reward: 744.1, e: 0.4, savings: 5800, debt: -1993,\n",
      "episode: 183/1001, reward: 851.8, e: 0.4, savings: 1637, debt: -1338,\n",
      "episode: 184/1001, reward: 2.856e+03, e: 0.4, savings: 5992, debt: -1980,\n",
      "episode: 185/1001, reward: 4.392e+03, e: 0.4, savings: 5976, debt: -1940,\n",
      "episode: 186/1001, reward: 828.7, e: 0.39, savings: 4155, debt: -841,\n",
      "episode: 187/1001, reward: 785.9, e: 0.39, savings: 3629, debt: -978,\n",
      "episode: 188/1001, reward: 479.7, e: 0.39, savings: 5055, debt: -1671,\n",
      "episode: 189/1001, reward: 762.8, e: 0.39, savings: 2544, debt: -1123,\n",
      "episode: 190/1001, reward: 1.3e+03, e: 0.39, savings: 5826, debt: -1826,\n",
      "episode: 191/1001, reward: 832.1, e: 0.38, savings: 2201, debt: -701,\n",
      "episode: 192/1001, reward: 782.0, e: 0.38, savings: 4144, debt: -983,\n",
      "episode: 193/1001, reward: 1.161e+03, e: 0.38, savings: 2100, debt: -539,\n",
      "episode: 194/1001, reward: 1.033e+03, e: 0.38, savings: 2726, debt: -750,\n",
      "episode: 195/1001, reward: 1.411e+03, e: 0.38, savings: 5930, debt: -1887,\n",
      "episode: 196/1001, reward: 995.7, e: 0.37, savings: 2258, debt: -722,\n",
      "episode: 197/1001, reward: 548.4, e: 0.37, savings: 5300, debt: -1986,\n",
      "episode: 198/1001, reward: 818.0, e: 0.37, savings: 3719, debt: -850,\n",
      "episode: 199/1001, reward: 779.3, e: 0.37, savings: 3631, debt: -950,\n",
      "episode: 200/1001, reward: 462.8, e: 0.37, savings: 3670, debt: -1566,\n",
      "episode: 201/1001, reward: 1.095e+03, e: 0.37, savings: 2210, debt: -585,\n",
      "episode: 202/1001, reward: 1.185e+03, e: 0.36, savings: 2723, debt: -635,\n",
      "episode: 203/1001, reward: 1.177e+03, e: 0.36, savings: 2687, debt: -600,\n",
      "episode: 204/1001, reward: 533.0, e: 0.36, savings: 987, debt: -1701,\n",
      "episode: 205/1001, reward: 647.0, e: 0.36, savings: 3737, debt: -1065,\n",
      "episode: 206/1001, reward: 579.7, e: 0.36, savings: 662, debt: -1728,\n",
      "episode: 207/1001, reward: 742.3, e: 0.35, savings: 3090, debt: -1077,\n",
      "episode: 208/1001, reward: 572.5, e: 0.35, savings: 5267, debt: -1959,\n",
      "episode: 209/1001, reward: 829.5, e: 0.35, savings: 3683, debt: -947,\n",
      "episode: 210/1001, reward: 542.4, e: 0.35, savings: 4030, debt: -1180,\n",
      "episode: 211/1001, reward: 827.5, e: 0.35, savings: 2435, debt: -1408,\n",
      "episode: 212/1001, reward: 772.4, e: 0.35, savings: 3952, debt: -956,\n",
      "episode: 213/1001, reward: 785.5, e: 0.34, savings: 605, debt: -1449,\n",
      "episode: 214/1001, reward: 1.464e+03, e: 0.34, savings: 5931, debt: -1834,\n",
      "episode: 215/1001, reward: 1.725e+03, e: 0.34, savings: 751, debt: -153,\n",
      "episode: 216/1001, reward: 923.9, e: 0.34, savings: 945, debt: -388,\n",
      "episode: 217/1001, reward: 791.7, e: 0.34, savings: 5606, debt: -1423,\n",
      "episode: 218/1001, reward: 834.3, e: 0.34, savings: 2994, debt: -1253,\n",
      "episode: 219/1001, reward: 1.246e+03, e: 0.33, savings: 2690, debt: -519,\n",
      "episode: 220/1001, reward: 851.3, e: 0.33, savings: 4042, debt: -868,\n",
      "episode: 221/1001, reward: 780.8, e: 0.33, savings: 5361, debt: -1898,\n",
      "episode: 222/1001, reward: 798.6, e: 0.33, savings: 5602, debt: -1952,\n",
      "episode: 223/1001, reward: 764.9, e: 0.33, savings: 3426, debt: -963,\n",
      "episode: 224/1001, reward: 1.209e+03, e: 0.33, savings: 5800, debt: -1797,\n",
      "episode: 225/1001, reward: 594.3, e: 0.32, savings: 4137, debt: -1079,\n",
      "episode: 226/1001, reward: 656.1, e: 0.32, savings: 718, debt: -1239,\n",
      "episode: 227/1001, reward: 1.03e+03, e: 0.32, savings: 2997, debt: -877,\n",
      "episode: 228/1001, reward: 1.05e+03, e: 0.32, savings: 2617, debt: -703,\n",
      "episode: 229/1001, reward: 867.4, e: 0.32, savings: 3135, debt: -949,\n",
      "episode: 230/1001, reward: 778.3, e: 0.32, savings: 3158, debt: -1203,\n",
      "episode: 231/1001, reward: 666.0, e: 0.31, savings: 2236, debt: -1052,\n",
      "episode: 232/1001, reward: 988.7, e: 0.31, savings: 2687, debt: -842,\n",
      "episode: 233/1001, reward: 835.9, e: 0.31, savings: 2824, debt: -1397,\n",
      "episode: 234/1001, reward: 818.9, e: 0.31, savings: 3222, debt: -1098,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 235/1001, reward: 831.8, e: 0.31, savings: 3324, debt: -1049,\n",
      "episode: 236/1001, reward: 446.2, e: 0.31, savings: 1847, debt: -1535,\n",
      "episode: 237/1001, reward: 763.8, e: 0.3, savings: 910, debt: -620,\n",
      "episode: 238/1001, reward: 1.057e+03, e: 0.3, savings: 2361, debt: -660,\n",
      "episode: 239/1001, reward: 741.8, e: 0.3, savings: 2153, debt: -1501,\n",
      "episode: 240/1001, reward: 1.091e+03, e: 0.3, savings: 1079, debt: -351,\n",
      "episode: 241/1001, reward: 838.3, e: 0.3, savings: 2752, debt: -1318,\n",
      "episode: 242/1001, reward: 537.6, e: 0.3, savings: 1865, debt: -1372,\n",
      "episode: 243/1001, reward: 847.3, e: 0.3, savings: 3327, debt: -902,\n",
      "episode: 244/1001, reward: 860.8, e: 0.29, savings: 3511, debt: -1110,\n",
      "episode: 245/1001, reward: 809.7, e: 0.29, savings: 3172, debt: -1141,\n",
      "episode: 246/1001, reward: 822.5, e: 0.29, savings: 2237, debt: -1212,\n",
      "episode: 247/1001, reward: 835.2, e: 0.29, savings: 3485, debt: -1064,\n",
      "episode: 248/1001, reward: 980.7, e: 0.29, savings: 2832, debt: -915,\n",
      "episode: 249/1001, reward: 1.007e+03, e: 0.29, savings: 2812, debt: -911,\n",
      "episode: 250/1001, reward: 1.063e+03, e: 0.29, savings: 2656, debt: -752,\n",
      "episode: 251/1001, reward: 1.36e+03, e: 0.28, savings: 897, debt: -274,\n",
      "episode: 252/1001, reward: 1.038e+03, e: 0.28, savings: 2643, debt: -844,\n",
      "episode: 253/1001, reward: 723.1, e: 0.28, savings: 2664, debt: -1568,\n",
      "episode: 254/1001, reward: 793.1, e: 0.28, savings: 3613, debt: -970,\n",
      "episode: 255/1001, reward: 776.6, e: 0.28, savings: 3312, debt: -988,\n",
      "episode: 256/1001, reward: 799.3, e: 0.28, savings: 3383, debt: -1019,\n",
      "episode: 257/1001, reward: 865.6, e: 0.28, savings: 1359, debt: -1535,\n",
      "episode: 258/1001, reward: 841.3, e: 0.27, savings: 1400, debt: -1579,\n",
      "episode: 259/1001, reward: 783.5, e: 0.27, savings: 4252, debt: -991,\n",
      "episode: 260/1001, reward: 828.2, e: 0.27, savings: 3765, debt: -992,\n",
      "episode: 261/1001, reward: 676.6, e: 0.27, savings: 584, debt: -1241,\n",
      "episode: 262/1001, reward: 825.9, e: 0.27, savings: 1624, debt: -1574,\n",
      "episode: 263/1001, reward: 835.5, e: 0.27, savings: 3407, debt: -1273,\n",
      "episode: 264/1001, reward: 1.076e+03, e: 0.27, savings: 2604, debt: -769,\n",
      "episode: 265/1001, reward: 999.0, e: 0.26, savings: 3082, debt: -833,\n",
      "episode: 266/1001, reward: 775.3, e: 0.26, savings: 5840, debt: -1995,\n",
      "episode: 267/1001, reward: 405.7, e: 0.26, savings: 4914, debt: -1778,\n",
      "episode: 268/1001, reward: 838.9, e: 0.26, savings: 5397, debt: -1902,\n",
      "episode: 269/1001, reward: 892.2, e: 0.26, savings: 2605, debt: -1197,\n",
      "episode: 270/1001, reward: 1.199e+03, e: 0.26, savings: 5762, debt: -1666,\n",
      "episode: 271/1001, reward: 1.609e+03, e: 0.26, savings: 5752, debt: -1677,\n",
      "episode: 272/1001, reward: 1.657e+03, e: 0.26, savings: 449, debt: -118,\n",
      "episode: 273/1001, reward: 891.4, e: 0.25, savings: 2153, debt: -944,\n",
      "episode: 274/1001, reward: 988.5, e: 0.25, savings: 2707, debt: -903,\n",
      "episode: 275/1001, reward: 811.8, e: 0.25, savings: 3759, debt: -904,\n",
      "episode: 276/1001, reward: 3.478e+03, e: 0.25, savings: 5952, debt: -1880,\n",
      "episode: 277/1001, reward: 953.9, e: 0.25, savings: 2684, debt: -983,\n",
      "episode: 278/1001, reward: 833.8, e: 0.25, savings: 3670, debt: -1154,\n",
      "episode: 279/1001, reward: 1.91e+03, e: 0.25, savings: 5313, debt: -1095,\n",
      "episode: 280/1001, reward: 559.7, e: 0.25, savings: 2833, debt: -1839,\n",
      "episode: 281/1001, reward: 727.3, e: 0.24, savings: 2415, debt: -941,\n",
      "episode: 282/1001, reward: 444.5, e: 0.24, savings: 4465, debt: -1631,\n",
      "episode: 283/1001, reward: 825.2, e: 0.24, savings: 3013, debt: -1112,\n",
      "episode: 284/1001, reward: 798.8, e: 0.24, savings: 4165, debt: -894,\n",
      "episode: 285/1001, reward: 857.9, e: 0.24, savings: 3276, debt: -1213,\n",
      "episode: 286/1001, reward: 427.9, e: 0.24, savings: 5106, debt: -1684,\n",
      "episode: 287/1001, reward: 917.6, e: 0.24, savings: 2215, debt: -893,\n",
      "episode: 288/1001, reward: 1.301e+03, e: 0.24, savings: 5731, debt: -1530,\n",
      "episode: 289/1001, reward: 745.2, e: 0.23, savings: 3098, debt: -1043,\n",
      "episode: 290/1001, reward: 907.3, e: 0.23, savings: 2906, debt: -838,\n",
      "episode: 291/1001, reward: 824.2, e: 0.23, savings: 3620, debt: -1123,\n",
      "episode: 292/1001, reward: 1.209e+03, e: 0.23, savings: 1414, debt: -395,\n",
      "episode: 293/1001, reward: 829.8, e: 0.23, savings: 3585, debt: -1345,\n",
      "episode: 294/1001, reward: 1.252e+03, e: 0.23, savings: 2814, debt: -615,\n",
      "episode: 295/1001, reward: 1.038e+03, e: 0.23, savings: 2623, debt: -863,\n",
      "episode: 296/1001, reward: 1.167e+03, e: 0.23, savings: 2964, debt: -752,\n",
      "episode: 297/1001, reward: 635.8, e: 0.23, savings: 1942, debt: -1117,\n",
      "episode: 298/1001, reward: 692.2, e: 0.22, savings: 1885, debt: -1188,\n",
      "episode: 299/1001, reward: 711.1, e: 0.22, savings: 4106, debt: -1132,\n",
      "episode: 300/1001, reward: 1.187e+03, e: 0.22, savings: 2600, debt: -658,\n",
      "episode: 301/1001, reward: 1.049e+03, e: 0.22, savings: 2450, debt: -720,\n",
      "episode: 302/1001, reward: 616.9, e: 0.22, savings: 1342, debt: -1042,\n",
      "episode: 303/1001, reward: 1.121e+03, e: 0.22, savings: 2687, debt: -729,\n",
      "episode: 304/1001, reward: 874.5, e: 0.22, savings: 3976, debt: -1205,\n",
      "episode: 305/1001, reward: 1.098e+03, e: 0.22, savings: 2626, debt: -782,\n",
      "episode: 306/1001, reward: 886.2, e: 0.22, savings: 2871, debt: -1252,\n",
      "episode: 307/1001, reward: 570.2, e: 0.21, savings: 5310, debt: -1130,\n",
      "episode: 308/1001, reward: 823.6, e: 0.21, savings: 2420, debt: -661,\n",
      "episode: 309/1001, reward: 845.0, e: 0.21, savings: 3835, debt: -1099,\n",
      "episode: 310/1001, reward: 867.9, e: 0.21, savings: 3694, debt: -1084,\n",
      "episode: 311/1001, reward: 1.142e+03, e: 0.21, savings: 2488, debt: -655,\n",
      "episode: 312/1001, reward: 943.1, e: 0.21, savings: 2165, debt: -925,\n",
      "episode: 313/1001, reward: 905.7, e: 0.21, savings: 2466, debt: -1068,\n",
      "episode: 314/1001, reward: 797.5, e: 0.21, savings: 3214, debt: -912,\n",
      "episode: 315/1001, reward: 872.1, e: 0.21, savings: 3943, debt: -1043,\n",
      "episode: 316/1001, reward: 838.6, e: 0.21, savings: 3753, debt: -1232,\n",
      "episode: 317/1001, reward: 892.6, e: 0.2, savings: 2270, debt: -1025,\n",
      "episode: 318/1001, reward: 1.416e+03, e: 0.2, savings: 1157, debt: -318,\n",
      "episode: 319/1001, reward: 907.6, e: 0.2, savings: 2829, debt: -1298,\n",
      "episode: 320/1001, reward: 1.113e+03, e: 0.2, savings: 2750, debt: -726,\n",
      "episode: 321/1001, reward: 1.535e+03, e: 0.2, savings: 5728, debt: -1617,\n",
      "episode: 322/1001, reward: 835.6, e: 0.2, savings: 3423, debt: -1058,\n",
      "episode: 323/1001, reward: 1.177e+03, e: 0.2, savings: 2862, debt: -709,\n",
      "episode: 324/1001, reward: 847.1, e: 0.2, savings: 3860, debt: -1126,\n",
      "episode: 325/1001, reward: 1.361e+03, e: 0.2, savings: 2948, debt: -542,\n",
      "episode: 326/1001, reward: 1.072e+03, e: 0.2, savings: 2158, debt: -662,\n",
      "episode: 327/1001, reward: 900.4, e: 0.19, savings: 2183, debt: -951,\n",
      "episode: 328/1001, reward: 1.317e+03, e: 0.19, savings: 2726, debt: -591,\n",
      "episode: 329/1001, reward: 775.4, e: 0.19, savings: 2594, debt: -1688,\n",
      "episode: 330/1001, reward: 846.1, e: 0.19, savings: 4155, debt: -1040,\n",
      "episode: 331/1001, reward: 7.836e+03, e: 0.19, savings: 5714, debt: -1546,\n",
      "episode: 332/1001, reward: 1.906e+03, e: 0.19, savings: 5663, debt: -1709,\n",
      "episode: 333/1001, reward: 880.0, e: 0.19, savings: 3502, debt: -1097,\n",
      "episode: 334/1001, reward: 904.2, e: 0.19, savings: 2337, debt: -1095,\n",
      "episode: 335/1001, reward: 866.9, e: 0.19, savings: 3819, debt: -1122,\n",
      "episode: 336/1001, reward: 883.4, e: 0.19, savings: 3943, debt: -1149,\n",
      "episode: 337/1001, reward: 2.043e+03, e: 0.18, savings: 5740, debt: -1598,\n",
      "episode: 338/1001, reward: 2.296e+03, e: 0.18, savings: 5667, debt: -1777,\n",
      "episode: 339/1001, reward: 798.7, e: 0.18, savings: 3839, debt: -957,\n",
      "episode: 340/1001, reward: 4.047e+03, e: 0.18, savings: 5955, debt: -1969,\n",
      "episode: 341/1001, reward: 731.0, e: 0.18, savings: 2720, debt: -985,\n",
      "episode: 342/1001, reward: 785.8, e: 0.18, savings: 4611, debt: -984,\n",
      "episode: 343/1001, reward: 868.9, e: 0.18, savings: 3993, debt: -1077,\n",
      "episode: 344/1001, reward: 412.1, e: 0.18, savings: 5240, debt: -1833,\n",
      "episode: 345/1001, reward: 816.7, e: 0.18, savings: 5687, debt: -1968,\n",
      "episode: 346/1001, reward: 1.119e+03, e: 0.18, savings: 4937, debt: -1643,\n",
      "episode: 347/1001, reward: 418.9, e: 0.18, savings: 5235, debt: -1804,\n",
      "episode: 348/1001, reward: 966.2, e: 0.17, savings: 1320, debt: -339,\n",
      "episode: 349/1001, reward: 747.2, e: 0.17, savings: 2696, debt: -968,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 350/1001, reward: 810.4, e: 0.17, savings: 4495, debt: -919,\n",
      "episode: 351/1001, reward: 798.2, e: 0.17, savings: 3514, debt: -947,\n",
      "episode: 352/1001, reward: 887.6, e: 0.17, savings: 2229, debt: -1076,\n",
      "episode: 353/1001, reward: 1.492e+03, e: 0.17, savings: 5790, debt: -1488,\n",
      "episode: 354/1001, reward: 2.223e+03, e: 0.17, savings: 1048, debt: -77,\n",
      "episode: 355/1001, reward: 1.295e+03, e: 0.17, savings: 5824, debt: -1560,\n",
      "episode: 356/1001, reward: 788.0, e: 0.17, savings: 3410, debt: -984,\n",
      "episode: 357/1001, reward: 410.5, e: 0.17, savings: 4967, debt: -1803,\n",
      "episode: 358/1001, reward: 1.351e+03, e: 0.17, savings: 4269, debt: -218,\n",
      "episode: 359/1001, reward: 1.338e+03, e: 0.17, savings: 5719, debt: -1552,\n",
      "episode: 360/1001, reward: 847.4, e: 0.16, savings: 2699, debt: -1598,\n",
      "episode: 361/1001, reward: 4.09e+03, e: 0.16, savings: 5643, debt: -1610,\n",
      "episode: 362/1001, reward: 2.033e+03, e: 0.16, savings: 4541, debt: -105,\n",
      "episode: 363/1001, reward: 817.4, e: 0.16, savings: 4576, debt: -890,\n",
      "episode: 364/1001, reward: 858.5, e: 0.16, savings: 2630, debt: -1576,\n",
      "episode: 365/1001, reward: 805.1, e: 0.16, savings: 4365, debt: -950,\n",
      "episode: 366/1001, reward: 1.218e+03, e: 0.16, savings: 4570, debt: -77,\n",
      "episode: 367/1001, reward: 858.5, e: 0.16, savings: 2626, debt: -1497,\n",
      "episode: 368/1001, reward: 889.4, e: 0.16, savings: 2638, debt: -1679,\n",
      "episode: 369/1001, reward: 610.9, e: 0.16, savings: 4992, debt: -1017,\n",
      "episode: 370/1001, reward: 858.7, e: 0.16, savings: 2577, debt: -1508,\n",
      "episode: 371/1001, reward: 831.2, e: 0.16, savings: 2843, debt: -1500,\n",
      "episode: 372/1001, reward: 765.6, e: 0.15, savings: 2117, debt: -1380,\n",
      "episode: 373/1001, reward: 833.3, e: 0.15, savings: 2713, debt: -1508,\n",
      "episode: 374/1001, reward: 1.746e+03, e: 0.15, savings: 5401, debt: -819,\n",
      "episode: 375/1001, reward: 1.8e+03, e: 0.15, savings: 5792, debt: -1480,\n",
      "episode: 376/1001, reward: 1.322e+03, e: 0.15, savings: 5747, debt: -1472,\n",
      "episode: 377/1001, reward: 1.743e+03, e: 0.15, savings: 5521, debt: -822,\n",
      "episode: 378/1001, reward: 906.0, e: 0.15, savings: 2377, debt: -1670,\n",
      "episode: 379/1001, reward: 1.465e+03, e: 0.15, savings: 5787, debt: -1474,\n",
      "episode: 380/1001, reward: 1.35e+03, e: 0.15, savings: 1695, debt: -268,\n",
      "episode: 381/1001, reward: 597.0, e: 0.15, savings: 4913, debt: -1061,\n",
      "episode: 382/1001, reward: 2.944e+03, e: 0.15, savings: 5280, debt: -771,\n",
      "episode: 383/1001, reward: 703.8, e: 0.15, savings: 2724, debt: -1064,\n",
      "episode: 384/1001, reward: 724.3, e: 0.15, savings: 2542, debt: -994,\n",
      "episode: 385/1001, reward: 859.9, e: 0.15, savings: 3480, debt: -1388,\n",
      "episode: 386/1001, reward: 938.2, e: 0.14, savings: 4144, debt: -268,\n",
      "episode: 387/1001, reward: 839.1, e: 0.14, savings: 4037, debt: -1009,\n",
      "episode: 388/1001, reward: 891.7, e: 0.14, savings: 2045, debt: -1708,\n",
      "episode: 389/1001, reward: 1.836e+03, e: 0.14, savings: 5424, debt: -1059,\n",
      "episode: 390/1001, reward: 808.1, e: 0.14, savings: 4621, debt: -1856,\n",
      "episode: 391/1001, reward: 1.008e+03, e: 0.14, savings: 4316, debt: -176,\n",
      "episode: 392/1001, reward: 789.8, e: 0.14, savings: 3311, debt: -952,\n",
      "episode: 393/1001, reward: 756.5, e: 0.14, savings: 2954, debt: -960,\n",
      "episode: 394/1001, reward: 810.4, e: 0.14, savings: 4583, debt: -960,\n",
      "episode: 395/1001, reward: 2.103e+03, e: 0.14, savings: 5255, debt: -689,\n",
      "episode: 396/1001, reward: 374.8, e: 0.14, savings: 5205, debt: -1866,\n",
      "episode: 397/1001, reward: 966.6, e: 0.14, savings: 4818, debt: -468,\n",
      "episode: 398/1001, reward: 535.5, e: 0.14, savings: 5443, debt: -1280,\n",
      "episode: 399/1001, reward: 830.0, e: 0.14, savings: 2600, debt: -1523,\n",
      "episode: 400/1001, reward: 712.4, e: 0.13, savings: 2588, debt: -1001,\n",
      "episode: 401/1001, reward: 1.598e+03, e: 0.13, savings: 5771, debt: -1434,\n",
      "episode: 402/1001, reward: 798.4, e: 0.13, savings: 4792, debt: -934,\n",
      "episode: 403/1001, reward: 1.879e+03, e: 0.13, savings: 5004, debt: -649,\n",
      "episode: 404/1001, reward: 841.1, e: 0.13, savings: 3042, debt: -1488,\n",
      "episode: 405/1001, reward: 902.9, e: 0.13, savings: 2413, debt: -1688,\n",
      "episode: 406/1001, reward: 1.753e+03, e: 0.13, savings: 5809, debt: -1796,\n",
      "episode: 407/1001, reward: 750.4, e: 0.13, savings: 3186, debt: -1021,\n",
      "episode: 408/1001, reward: 741.0, e: 0.13, savings: 3036, debt: -1028,\n",
      "episode: 409/1001, reward: 768.1, e: 0.13, savings: 3065, debt: -973,\n",
      "episode: 410/1001, reward: 817.2, e: 0.13, savings: 5125, debt: -178,\n",
      "episode: 411/1001, reward: 370.0, e: 0.13, savings: 5189, debt: -1924,\n",
      "episode: 412/1001, reward: 1.141e+03, e: 0.13, savings: 5251, debt: -1475,\n",
      "episode: 413/1001, reward: 1.257e+03, e: 0.13, savings: 5580, debt: -1495,\n",
      "episode: 414/1001, reward: 1.25e+03, e: 0.13, savings: 5935, debt: -1922,\n",
      "episode: 415/1001, reward: 1.212e+03, e: 0.12, savings: 5647, debt: -1372,\n",
      "episode: 416/1001, reward: 1.266e+03, e: 0.12, savings: 5638, debt: -1405,\n",
      "episode: 417/1001, reward: 1.038e+03, e: 0.12, savings: 1276, debt: -304,\n",
      "episode: 418/1001, reward: 1.378e+03, e: 0.12, savings: 5654, debt: -1696,\n",
      "episode: 419/1001, reward: 834.7, e: 0.12, savings: 2836, debt: -1479,\n",
      "episode: 420/1001, reward: 865.1, e: 0.12, savings: 2847, debt: -1521,\n",
      "episode: 421/1001, reward: 1.247e+03, e: 0.12, savings: 5620, debt: -1396,\n",
      "episode: 422/1001, reward: 1.308e+03, e: 0.12, savings: 5707, debt: -1372,\n",
      "episode: 423/1001, reward: 1.292e+03, e: 0.12, savings: 5776, debt: -1440,\n",
      "episode: 424/1001, reward: 405.5, e: 0.12, savings: 5254, debt: -1904,\n",
      "episode: 425/1001, reward: 1.281e+03, e: 0.12, savings: 5731, debt: -1507,\n",
      "episode: 426/1001, reward: 774.3, e: 0.12, savings: 3248, debt: -990,\n",
      "episode: 427/1001, reward: 1.334e+03, e: 0.12, savings: 5747, debt: -1374,\n",
      "episode: 428/1001, reward: 1.294e+03, e: 0.12, savings: 5676, debt: -1239,\n",
      "episode: 429/1001, reward: 911.0, e: 0.12, savings: 2531, debt: -1647,\n",
      "episode: 430/1001, reward: 865.1, e: 0.12, savings: 2418, debt: -1654,\n",
      "episode: 431/1001, reward: 890.9, e: 0.12, savings: 2225, debt: -1711,\n",
      "episode: 432/1001, reward: 917.2, e: 0.11, savings: 2335, debt: -1699,\n",
      "episode: 433/1001, reward: 791.5, e: 0.11, savings: 3237, debt: -1736,\n",
      "episode: 434/1001, reward: 1.34e+03, e: 0.11, savings: 5764, debt: -1459,\n",
      "episode: 435/1001, reward: 2.243e+03, e: 0.11, savings: 5416, debt: -837,\n",
      "episode: 436/1001, reward: 2.498e+03, e: 0.11, savings: 5852, debt: -1835,\n",
      "episode: 437/1001, reward: 1.747e+03, e: 0.11, savings: 5282, debt: -760,\n",
      "episode: 438/1001, reward: 830.9, e: 0.11, savings: 4579, debt: -826,\n",
      "episode: 439/1001, reward: 559.3, e: 0.11, savings: 652, debt: -1872,\n",
      "episode: 440/1001, reward: 419.3, e: 0.11, savings: 5330, debt: -1748,\n",
      "episode: 441/1001, reward: 788.6, e: 0.11, savings: 3393, debt: -954,\n",
      "episode: 442/1001, reward: 1.395e+03, e: 0.11, savings: 5722, debt: -1670,\n",
      "episode: 443/1001, reward: 847.3, e: 0.11, savings: 2700, debt: -394,\n",
      "episode: 444/1001, reward: 1.635e+03, e: 0.11, savings: 5427, debt: -672,\n",
      "episode: 445/1001, reward: 708.5, e: 0.11, savings: 4367, debt: -1138,\n",
      "episode: 446/1001, reward: 1.789e+03, e: 0.11, savings: 5747, debt: -1804,\n",
      "episode: 447/1001, reward: 913.9, e: 0.11, savings: 2629, debt: -1752,\n",
      "episode: 448/1001, reward: 745.1, e: 0.11, savings: 2681, debt: -1174,\n",
      "episode: 449/1001, reward: 777.4, e: 0.11, savings: 2601, debt: -1150,\n",
      "episode: 450/1001, reward: 816.0, e: 0.1, savings: 2886, debt: -1312,\n",
      "episode: 451/1001, reward: 815.6, e: 0.1, savings: 3030, debt: -1415,\n",
      "episode: 452/1001, reward: 805.4, e: 0.1, savings: 3140, debt: -1395,\n",
      "episode: 453/1001, reward: 789.9, e: 0.1, savings: 3162, debt: -1296,\n",
      "episode: 454/1001, reward: 757.6, e: 0.1, savings: 3066, debt: -995,\n",
      "episode: 455/1001, reward: 854.3, e: 0.1, savings: 3177, debt: -1411,\n",
      "episode: 456/1001, reward: 797.1, e: 0.1, savings: 3102, debt: -1345,\n",
      "episode: 457/1001, reward: 833.2, e: 0.1, savings: 3236, debt: -1329,\n",
      "episode: 458/1001, reward: -4e+11, e: 0.1, savings: 4908, debt: -1502,\n",
      "episode: 459/1001, reward: 5.618e+03, e: 0.1, savings: 4991, debt: -724,\n",
      "episode: 460/1001, reward: 2.97e+03, e: 0.1, savings: 5474, debt: -747,\n",
      "episode: 461/1001, reward: 1.778e+03, e: 0.099, savings: 5239, debt: -724,\n",
      "episode: 462/1001, reward: 5.509e+03, e: 0.099, savings: 5666, debt: -1657,\n",
      "episode: 463/1001, reward: 1.942e+03, e: 0.098, savings: 5952, debt: -1932,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 464/1001, reward: 368.3, e: 0.098, savings: 5598, debt: -1899,\n",
      "episode: 465/1001, reward: 907.4, e: 0.097, savings: 2375, debt: -1721,\n",
      "episode: 466/1001, reward: 979.3, e: 0.097, savings: 4249, debt: -201,\n",
      "episode: 467/1001, reward: 917.4, e: 0.096, savings: 2402, debt: -1792,\n",
      "episode: 468/1001, reward: 860.7, e: 0.096, savings: 3548, debt: -1345,\n",
      "episode: 469/1001, reward: 588.4, e: 0.095, savings: 1281, debt: -1072,\n",
      "episode: 470/1001, reward: 627.7, e: 0.095, savings: 1770, debt: -1120,\n",
      "episode: 471/1001, reward: 669.8, e: 0.094, savings: 2318, debt: -1031,\n",
      "episode: 472/1001, reward: 703.0, e: 0.094, savings: 2476, debt: -1018,\n",
      "episode: 473/1001, reward: 564.7, e: 0.093, savings: 3378, debt: -1792,\n",
      "episode: 474/1001, reward: 694.2, e: 0.093, savings: 2521, debt: -1026,\n",
      "episode: 475/1001, reward: 369.8, e: 0.092, savings: 4581, debt: -1869,\n",
      "episode: 476/1001, reward: 604.2, e: 0.092, savings: 3297, debt: -1740,\n",
      "episode: 477/1001, reward: 701.1, e: 0.092, savings: 2682, debt: -1050,\n",
      "episode: 478/1001, reward: 1.152e+03, e: 0.091, savings: 620, debt: -295,\n",
      "episode: 479/1001, reward: 1.912e+03, e: 0.091, savings: 5203, debt: -608,\n",
      "episode: 480/1001, reward: 2.667e+03, e: 0.09, savings: 5379, debt: -650,\n",
      "episode: 481/1001, reward: 2.553e+03, e: 0.09, savings: 5284, debt: -654,\n",
      "episode: 482/1001, reward: 1.081e+03, e: 0.089, savings: 4604, debt: -1535,\n",
      "episode: 483/1001, reward: 882.8, e: 0.089, savings: 4780, debt: -425,\n",
      "episode: 484/1001, reward: 888.0, e: 0.088, savings: 4663, debt: -658,\n",
      "episode: 485/1001, reward: 972.9, e: 0.088, savings: 4119, debt: -644,\n",
      "episode: 486/1001, reward: 676.8, e: 0.088, savings: 3371, debt: -1799,\n",
      "episode: 487/1001, reward: 740.2, e: 0.087, savings: 2858, debt: -994,\n",
      "episode: 488/1001, reward: 741.5, e: 0.087, savings: 2889, debt: -1006,\n",
      "episode: 489/1001, reward: 364.7, e: 0.086, savings: 5619, debt: -1945,\n",
      "episode: 490/1001, reward: 2.598e+03, e: 0.086, savings: 5237, debt: -657,\n",
      "episode: 491/1001, reward: 1.666e+03, e: 0.085, savings: 4863, debt: -1396,\n",
      "episode: 492/1001, reward: 1.1e+03, e: 0.085, savings: 4755, debt: -1374,\n",
      "episode: 493/1001, reward: 607.8, e: 0.084, savings: 4252, debt: -1899,\n",
      "episode: 494/1001, reward: 1.404e+03, e: 0.084, savings: 5848, debt: -1620,\n",
      "episode: 495/1001, reward: 1.191e+03, e: 0.084, savings: 5248, debt: -1386,\n",
      "episode: 496/1001, reward: 662.5, e: 0.083, savings: 3658, debt: -1653,\n",
      "episode: 497/1001, reward: 807.8, e: 0.083, savings: 3618, debt: -939,\n",
      "episode: 498/1001, reward: 1.192e+03, e: 0.082, savings: 5364, debt: -1451,\n",
      "episode: 499/1001, reward: 4.003e+03, e: 0.082, savings: 5714, debt: -1546,\n",
      "episode: 500/1001, reward: 854.1, e: 0.082, savings: 3591, debt: -1275,\n",
      "episode: 501/1001, reward: 852.2, e: 0.081, savings: 3654, debt: -1375,\n",
      "episode: 502/1001, reward: 426.5, e: 0.081, savings: 5415, debt: -1968,\n",
      "episode: 503/1001, reward: 869.5, e: 0.08, savings: 3750, debt: -1341,\n",
      "episode: 504/1001, reward: 851.1, e: 0.08, savings: 3609, debt: -1284,\n",
      "episode: 505/1001, reward: 838.0, e: 0.08, savings: 3082, debt: -1533,\n",
      "episode: 506/1001, reward: 823.0, e: 0.079, savings: 2865, debt: -1479,\n",
      "episode: 507/1001, reward: 721.0, e: 0.079, savings: 4665, debt: -1100,\n",
      "episode: 508/1001, reward: 1.445e+03, e: 0.078, savings: 3235, debt: -582,\n",
      "episode: 509/1001, reward: 1.695e+03, e: 0.078, savings: 3217, debt: -455,\n",
      "episode: 510/1001, reward: 1.113e+03, e: 0.078, savings: 4848, debt: -1401,\n",
      "episode: 511/1001, reward: 1.636e+03, e: 0.077, savings: 2125, debt: -367,\n",
      "episode: 512/1001, reward: 3.351e+03, e: 0.077, savings: 522, debt: -51,\n",
      "episode: 513/1001, reward: 1.703e+03, e: 0.076, savings: 3151, debt: -430,\n",
      "episode: 514/1001, reward: 1.799e+03, e: 0.076, savings: 2877, debt: -358,\n",
      "episode: 515/1001, reward: 1.879e+03, e: 0.076, savings: 3345, debt: -383,\n",
      "episode: 516/1001, reward: 362.4, e: 0.075, savings: 5330, debt: -1973,\n",
      "episode: 517/1001, reward: 507.7, e: 0.075, savings: 4584, debt: -1882,\n",
      "episode: 518/1001, reward: 498.1, e: 0.075, savings: 5131, debt: -1892,\n",
      "episode: 519/1001, reward: 806.2, e: 0.074, savings: 4576, debt: -740,\n",
      "episode: 520/1001, reward: 801.6, e: 0.074, savings: 3929, debt: -979,\n",
      "episode: 521/1001, reward: 5.624e+03, e: 0.073, savings: 5540, debt: -1395,\n",
      "episode: 522/1001, reward: 876.5, e: 0.073, savings: 3882, debt: -1291,\n",
      "episode: 523/1001, reward: 1.155e+03, e: 0.073, savings: 5770, debt: -1865,\n",
      "episode: 524/1001, reward: 1.191e+03, e: 0.072, savings: 5805, debt: -1884,\n",
      "episode: 525/1001, reward: 875.3, e: 0.072, savings: 3701, debt: -1349,\n",
      "episode: 526/1001, reward: 856.3, e: 0.072, savings: 3546, debt: -1353,\n",
      "episode: 527/1001, reward: 1.111e+03, e: 0.071, savings: 4771, debt: -1414,\n",
      "episode: 528/1001, reward: 2.391e+03, e: 0.071, savings: 4947, debt: -663,\n",
      "episode: 529/1001, reward: 2.368e+03, e: 0.071, savings: 5398, debt: -606,\n",
      "episode: 530/1001, reward: 1.904e+03, e: 0.07, savings: 5327, debt: -572,\n",
      "episode: 531/1001, reward: 849.6, e: 0.07, savings: 3707, debt: -1274,\n",
      "episode: 532/1001, reward: 875.6, e: 0.069, savings: 3700, debt: -1307,\n",
      "episode: 533/1001, reward: 377.1, e: 0.069, savings: 5537, debt: -1949,\n",
      "episode: 534/1001, reward: 841.7, e: 0.069, savings: 3774, debt: -1275,\n",
      "episode: 535/1001, reward: 3.638e+03, e: 0.068, savings: 3393, debt: -114,\n",
      "episode: 536/1001, reward: 866.8, e: 0.068, savings: 3231, debt: -1478,\n",
      "episode: 537/1001, reward: 823.2, e: 0.068, savings: 3429, debt: -1347,\n",
      "episode: 538/1001, reward: 845.8, e: 0.067, savings: 3409, debt: -1343,\n",
      "episode: 539/1001, reward: 660.7, e: 0.067, savings: 3870, debt: -1793,\n",
      "episode: 540/1001, reward: 373.7, e: 0.067, savings: 5578, debt: -1898,\n",
      "episode: 541/1001, reward: 1.829e+03, e: 0.066, savings: 5340, debt: -598,\n",
      "episode: 542/1001, reward: 821.5, e: 0.066, savings: 4593, debt: -831,\n",
      "episode: 543/1001, reward: 1.066e+03, e: 0.066, savings: 4302, debt: -1537,\n",
      "episode: 544/1001, reward: 749.2, e: 0.065, savings: 2760, debt: -1371,\n",
      "episode: 545/1001, reward: 1.04e+03, e: 0.065, savings: 4290, debt: -740,\n",
      "episode: 546/1001, reward: 1.543e+03, e: 0.065, savings: 3920, debt: -421,\n",
      "episode: 547/1001, reward: 1.397e+03, e: 0.064, savings: 4692, debt: -1458,\n",
      "episode: 548/1001, reward: 766.4, e: 0.064, savings: 3330, debt: -1035,\n",
      "episode: 549/1001, reward: 1.119e+03, e: 0.064, savings: 5000, debt: -1484,\n",
      "episode: 550/1001, reward: 1.153e+03, e: 0.063, savings: 4866, debt: -1410,\n",
      "episode: 551/1001, reward: 488.7, e: 0.063, savings: 5191, debt: -1895,\n",
      "episode: 552/1001, reward: 822.0, e: 0.063, savings: 3427, debt: -1355,\n",
      "episode: 553/1001, reward: 1.156e+03, e: 0.063, savings: 4940, debt: -1383,\n",
      "episode: 554/1001, reward: 862.6, e: 0.062, savings: 3707, debt: -1357,\n",
      "episode: 555/1001, reward: 1.154e+03, e: 0.062, savings: 5234, debt: -1436,\n",
      "episode: 556/1001, reward: 863.5, e: 0.062, savings: 3460, debt: -1344,\n",
      "episode: 557/1001, reward: 1.157e+03, e: 0.061, savings: 5060, debt: -1386,\n",
      "episode: 558/1001, reward: 1.876e+03, e: 0.061, savings: 5548, debt: -1415,\n",
      "episode: 559/1001, reward: 1.695e+03, e: 0.061, savings: 5084, debt: -1247,\n",
      "episode: 560/1001, reward: 1.808e+03, e: 0.06, savings: 5235, debt: -590,\n",
      "episode: 561/1001, reward: 484.9, e: 0.06, savings: 4996, debt: -1897,\n",
      "episode: 562/1001, reward: 458.1, e: 0.06, savings: 4894, debt: -1909,\n",
      "episode: 563/1001, reward: 911.6, e: 0.059, savings: 4854, debt: -707,\n",
      "episode: 564/1001, reward: 434.6, e: 0.059, savings: 5402, debt: -1942,\n",
      "episode: 565/1001, reward: 861.6, e: 0.059, savings: 2842, debt: -1656,\n",
      "episode: 566/1001, reward: 705.4, e: 0.059, savings: 2486, debt: -1050,\n",
      "episode: 567/1001, reward: 1.956e+03, e: 0.058, savings: 5215, debt: -589,\n",
      "episode: 568/1001, reward: 2.209e+03, e: 0.058, savings: 5419, debt: -652,\n",
      "episode: 569/1001, reward: 1.755e+03, e: 0.058, savings: 5311, debt: -532,\n",
      "episode: 570/1001, reward: 832.5, e: 0.057, savings: 3229, debt: -1426,\n",
      "episode: 571/1001, reward: 691.2, e: 0.057, savings: 2310, debt: -988,\n",
      "episode: 572/1001, reward: 1.079e+03, e: 0.057, savings: 4555, debt: -1370,\n",
      "episode: 573/1001, reward: 4.252e+03, e: 0.057, savings: 5820, debt: -1599,\n",
      "episode: 574/1001, reward: 863.6, e: 0.056, savings: 3289, debt: -1466,\n",
      "episode: 575/1001, reward: 862.5, e: 0.056, savings: 3162, debt: -1531,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 576/1001, reward: 1.361e+03, e: 0.056, savings: 5348, debt: -1610,\n",
      "episode: 577/1001, reward: 1.432e+03, e: 0.055, savings: 5460, debt: -1394,\n",
      "episode: 578/1001, reward: 365.0, e: 0.055, savings: 5623, debt: -1906,\n",
      "episode: 579/1001, reward: 889.0, e: 0.055, savings: 2414, debt: -1390,\n",
      "episode: 580/1001, reward: 789.5, e: 0.055, savings: 2172, debt: -1469,\n",
      "episode: 581/1001, reward: 927.3, e: 0.054, savings: 4949, debt: -703,\n",
      "episode: 582/1001, reward: 368.6, e: 0.054, savings: 5521, debt: -1912,\n",
      "episode: 583/1001, reward: 876.1, e: 0.054, savings: 2778, debt: -1594,\n",
      "episode: 584/1001, reward: 879.3, e: 0.054, savings: 5435, debt: -1966,\n",
      "episode: 585/1001, reward: 1.144e+03, e: 0.053, savings: 2642, debt: -741,\n",
      "episode: 586/1001, reward: 1.153e+03, e: 0.053, savings: 2843, debt: -787,\n",
      "episode: 587/1001, reward: 609.8, e: 0.053, savings: 1586, debt: -1061,\n",
      "episode: 588/1001, reward: 888.1, e: 0.052, savings: 4181, debt: -1149,\n",
      "episode: 589/1001, reward: 791.3, e: 0.052, savings: 2840, debt: -1638,\n",
      "episode: 590/1001, reward: 1.748e+03, e: 0.052, savings: 3263, debt: -390,\n",
      "episode: 591/1001, reward: 2.542e+03, e: 0.052, savings: 5341, debt: -672,\n",
      "episode: 592/1001, reward: 5.514e+03, e: 0.051, savings: 5840, debt: -1808,\n",
      "episode: 593/1001, reward: 843.5, e: 0.051, savings: 3116, debt: -1441,\n",
      "episode: 594/1001, reward: 1.884e+03, e: 0.051, savings: 5352, debt: -677,\n",
      "episode: 595/1001, reward: 850.4, e: 0.051, savings: 3292, debt: -1460,\n",
      "episode: 596/1001, reward: 817.1, e: 0.05, savings: 3911, debt: -947,\n",
      "episode: 597/1001, reward: 923.9, e: 0.05, savings: 2480, debt: -1801,\n",
      "episode: 598/1001, reward: 1.757e+03, e: 0.05, savings: 5391, debt: -533,\n",
      "episode: 599/1001, reward: 830.0, e: 0.05, savings: 4867, debt: -658,\n",
      "episode: 600/1001, reward: 697.5, e: 0.049, savings: 535, debt: -1819,\n",
      "episode: 601/1001, reward: 618.2, e: 0.049, savings: 1740, debt: -1087,\n",
      "episode: 602/1001, reward: 670.6, e: 0.049, savings: 2242, debt: -1043,\n",
      "episode: 603/1001, reward: 363.9, e: 0.049, savings: 5629, debt: -1934,\n",
      "episode: 604/1001, reward: 624.1, e: 0.048, savings: 4386, debt: -1849,\n",
      "episode: 605/1001, reward: 357.3, e: 0.048, savings: 5835, debt: -1989,\n",
      "episode: 606/1001, reward: 791.9, e: 0.048, savings: 3378, debt: -959,\n",
      "episode: 607/1001, reward: 847.1, e: 0.048, savings: 3657, debt: -1326,\n",
      "episode: 608/1001, reward: 864.3, e: 0.047, savings: 3742, debt: -1373,\n",
      "episode: 609/1001, reward: 861.4, e: 0.047, savings: 1344, debt: -811,\n",
      "episode: 610/1001, reward: 1.459e+03, e: 0.047, savings: 5985, debt: -1982,\n",
      "episode: 611/1001, reward: 862.8, e: 0.047, savings: 3719, debt: -1338,\n",
      "episode: 612/1001, reward: 1.368e+03, e: 0.047, savings: 5817, debt: -1689,\n",
      "episode: 613/1001, reward: 1.387e+03, e: 0.046, savings: 5599, debt: -1252,\n",
      "episode: 614/1001, reward: 1.406e+03, e: 0.046, savings: 5615, debt: -1292,\n",
      "episode: 615/1001, reward: 5.769e+03, e: 0.046, savings: 5572, debt: -1178,\n",
      "episode: 616/1001, reward: 1.401e+03, e: 0.046, savings: 5672, debt: -1180,\n",
      "episode: 617/1001, reward: 1.87e+03, e: 0.045, savings: 5127, debt: -568,\n",
      "episode: 618/1001, reward: 845.3, e: 0.045, savings: 3325, debt: -1464,\n",
      "episode: 619/1001, reward: 884.6, e: 0.045, savings: 5512, debt: -1956,\n",
      "episode: 620/1001, reward: 849.2, e: 0.045, savings: 3479, debt: -1398,\n",
      "episode: 621/1001, reward: -4e+11, e: 0.044, savings: 5384, debt: -558,\n",
      "episode: 622/1001, reward: 1.924e+03, e: 0.044, savings: 5751, debt: -1618,\n",
      "episode: 623/1001, reward: 552.0, e: 0.044, savings: 5200, debt: -1984,\n",
      "episode: 624/1001, reward: 777.0, e: 0.044, savings: 3267, debt: -998,\n",
      "episode: 625/1001, reward: 360.4, e: 0.044, savings: 5812, debt: -1974,\n",
      "episode: 626/1001, reward: 357.1, e: 0.043, savings: 5939, debt: -1952,\n",
      "episode: 627/1001, reward: 353.8, e: 0.043, savings: 5768, debt: -1916,\n",
      "episode: 628/1001, reward: 852.7, e: 0.043, savings: 3364, debt: -1421,\n",
      "episode: 629/1001, reward: 841.6, e: 0.043, savings: 3582, debt: -1351,\n",
      "episode: 630/1001, reward: 854.0, e: 0.043, savings: 3287, debt: -1497,\n",
      "episode: 631/1001, reward: 347.9, e: 0.042, savings: 5775, debt: -1989,\n",
      "episode: 632/1001, reward: 856.7, e: 0.042, savings: 3602, debt: -1349,\n",
      "episode: 633/1001, reward: 540.2, e: 0.042, savings: 2200, debt: -1924,\n",
      "episode: 634/1001, reward: 856.9, e: 0.042, savings: 3681, debt: -1288,\n",
      "episode: 635/1001, reward: 372.7, e: 0.041, savings: 5597, debt: -1952,\n",
      "episode: 636/1001, reward: 350.5, e: 0.041, savings: 5867, debt: -1971,\n",
      "episode: 637/1001, reward: 869.5, e: 0.041, savings: 3672, debt: -1381,\n",
      "episode: 638/1001, reward: 830.7, e: 0.041, savings: 3565, debt: -1344,\n",
      "episode: 639/1001, reward: 851.8, e: 0.041, savings: 3586, debt: -1312,\n",
      "episode: 640/1001, reward: 836.2, e: 0.04, savings: 3512, debt: -1382,\n",
      "episode: 641/1001, reward: 860.4, e: 0.04, savings: 3865, debt: -1327,\n",
      "episode: 642/1001, reward: 858.6, e: 0.04, savings: 3509, debt: -1365,\n",
      "episode: 643/1001, reward: 850.9, e: 0.04, savings: 3712, debt: -1300,\n",
      "episode: 644/1001, reward: 846.3, e: 0.04, savings: 3557, debt: -1387,\n",
      "episode: 645/1001, reward: 882.4, e: 0.039, savings: 3680, debt: -1326,\n",
      "episode: 646/1001, reward: 858.2, e: 0.039, savings: 3606, debt: -1333,\n",
      "episode: 647/1001, reward: 867.1, e: 0.039, savings: 3567, debt: -1416,\n",
      "episode: 648/1001, reward: 858.9, e: 0.039, savings: 3689, debt: -1391,\n",
      "episode: 649/1001, reward: 857.3, e: 0.039, savings: 3535, debt: -1414,\n",
      "episode: 650/1001, reward: 1.832e+03, e: 0.038, savings: 5384, debt: -535,\n",
      "episode: 651/1001, reward: 1.667e+03, e: 0.038, savings: 5208, debt: -516,\n",
      "episode: 652/1001, reward: 882.2, e: 0.038, savings: 3753, debt: -1289,\n",
      "episode: 653/1001, reward: 863.7, e: 0.038, savings: 3652, debt: -1360,\n",
      "episode: 654/1001, reward: 894.1, e: 0.038, savings: 1492, debt: -1791,\n",
      "episode: 655/1001, reward: 885.5, e: 0.038, savings: 1375, debt: -1805,\n",
      "episode: 656/1001, reward: 897.1, e: 0.037, savings: 1410, debt: -1798,\n",
      "episode: 657/1001, reward: 877.9, e: 0.037, savings: 3817, debt: -1305,\n",
      "episode: 658/1001, reward: 616.2, e: 0.037, savings: 4204, debt: -1877,\n",
      "episode: 659/1001, reward: 464.8, e: 0.037, savings: 5409, debt: -1816,\n",
      "episode: 660/1001, reward: 457.2, e: 0.037, savings: 5179, debt: -1920,\n",
      "episode: 661/1001, reward: 361.9, e: 0.036, savings: 5910, debt: -1984,\n",
      "episode: 662/1001, reward: 367.2, e: 0.036, savings: 5797, debt: -1956,\n",
      "episode: 663/1001, reward: 402.0, e: 0.036, savings: 5756, debt: -1817,\n",
      "episode: 664/1001, reward: 862.5, e: 0.036, savings: 3562, debt: -1433,\n",
      "episode: 665/1001, reward: 853.5, e: 0.036, savings: 3499, debt: -1376,\n",
      "episode: 666/1001, reward: 852.6, e: 0.035, savings: 3545, debt: -1383,\n",
      "episode: 667/1001, reward: 868.5, e: 0.035, savings: 3794, debt: -1313,\n",
      "episode: 668/1001, reward: 860.0, e: 0.035, savings: 3505, debt: -1424,\n",
      "episode: 669/1001, reward: 863.1, e: 0.035, savings: 3784, debt: -1261,\n",
      "episode: 670/1001, reward: 873.9, e: 0.035, savings: 3734, debt: -1353,\n",
      "episode: 671/1001, reward: 867.9, e: 0.035, savings: 3850, debt: -1289,\n",
      "episode: 672/1001, reward: 855.0, e: 0.034, savings: 3650, debt: -1391,\n",
      "episode: 673/1001, reward: 865.6, e: 0.034, savings: 3660, debt: -1400,\n",
      "episode: 674/1001, reward: 845.6, e: 0.034, savings: 3464, debt: -1297,\n",
      "episode: 675/1001, reward: 864.3, e: 0.034, savings: 3572, debt: -1422,\n",
      "episode: 676/1001, reward: 864.2, e: 0.034, savings: 3540, debt: -1440,\n",
      "episode: 677/1001, reward: 879.8, e: 0.034, savings: 3824, debt: -1323,\n",
      "episode: 678/1001, reward: 860.6, e: 0.033, savings: 3757, debt: -1348,\n",
      "episode: 679/1001, reward: 920.0, e: 0.033, savings: 2480, debt: -1801,\n",
      "episode: 680/1001, reward: 865.2, e: 0.033, savings: 3389, debt: -1468,\n",
      "episode: 681/1001, reward: 870.3, e: 0.033, savings: 3612, debt: -1401,\n",
      "episode: 682/1001, reward: 856.2, e: 0.033, savings: 3540, debt: -1420,\n",
      "episode: 683/1001, reward: 855.8, e: 0.033, savings: 3665, debt: -1386,\n",
      "episode: 684/1001, reward: 863.9, e: 0.032, savings: 3740, debt: -1318,\n",
      "episode: 685/1001, reward: 861.4, e: 0.032, savings: 3700, debt: -1402,\n",
      "episode: 686/1001, reward: 865.5, e: 0.032, savings: 3524, debt: -1423,\n",
      "episode: 687/1001, reward: 860.3, e: 0.032, savings: 3675, debt: -1375,\n",
      "episode: 688/1001, reward: 848.4, e: 0.032, savings: 3572, debt: -1382,\n",
      "episode: 689/1001, reward: 866.9, e: 0.032, savings: 3764, debt: -1260,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 690/1001, reward: 869.7, e: 0.031, savings: 3671, debt: -1339,\n",
      "episode: 691/1001, reward: 858.2, e: 0.031, savings: 3199, debt: -1476,\n",
      "episode: 692/1001, reward: 854.6, e: 0.031, savings: 3335, debt: -1496,\n",
      "episode: 693/1001, reward: 901.7, e: 0.031, savings: 1615, debt: -1805,\n",
      "episode: 694/1001, reward: 860.0, e: 0.031, savings: 3705, debt: -1368,\n",
      "episode: 695/1001, reward: 863.2, e: 0.031, savings: 3375, debt: -1495,\n",
      "episode: 696/1001, reward: 866.6, e: 0.031, savings: 3443, debt: -1357,\n",
      "episode: 697/1001, reward: 887.7, e: 0.03, savings: 3947, debt: -1297,\n",
      "episode: 698/1001, reward: 2.027e+03, e: 0.03, savings: 5592, debt: -1136,\n",
      "episode: 699/1001, reward: 870.9, e: 0.03, savings: 3474, debt: -1432,\n",
      "episode: 700/1001, reward: 866.3, e: 0.03, savings: 3366, debt: -1433,\n",
      "episode: 701/1001, reward: 881.7, e: 0.03, savings: 1087, debt: -1780,\n",
      "episode: 702/1001, reward: 900.3, e: 0.03, savings: 1859, debt: -1772,\n",
      "episode: 703/1001, reward: 878.8, e: 0.029, savings: 3827, debt: -1274,\n",
      "episode: 704/1001, reward: 912.9, e: 0.029, savings: 1790, debt: -1802,\n",
      "episode: 705/1001, reward: 855.5, e: 0.029, savings: 653, debt: -1611,\n",
      "episode: 706/1001, reward: 827.7, e: 0.029, savings: 5260, debt: -1963,\n",
      "episode: 707/1001, reward: 677.3, e: 0.029, savings: 2955, debt: -1914,\n",
      "episode: 708/1001, reward: 1.224e+03, e: 0.029, savings: 4763, debt: -230,\n",
      "episode: 709/1001, reward: 886.2, e: 0.029, savings: 3859, debt: -1256,\n",
      "episode: 710/1001, reward: 1.676e+03, e: 0.028, savings: 1204, debt: -115,\n",
      "episode: 711/1001, reward: 916.0, e: 0.028, savings: 2429, debt: -1768,\n",
      "episode: 712/1001, reward: 868.5, e: 0.028, savings: 3372, debt: -1481,\n",
      "episode: 713/1001, reward: 925.9, e: 0.028, savings: 2276, debt: -1761,\n",
      "episode: 714/1001, reward: 863.1, e: 0.028, savings: 3719, debt: -1275,\n",
      "episode: 715/1001, reward: 877.3, e: 0.028, savings: 554, debt: -1749,\n",
      "episode: 716/1001, reward: 866.8, e: 0.028, savings: 3777, debt: -1326,\n",
      "episode: 717/1001, reward: 1.383e+03, e: 0.027, savings: 3176, debt: -624,\n",
      "episode: 718/1001, reward: 1.452e+03, e: 0.027, savings: 3147, debt: -561,\n",
      "episode: 719/1001, reward: 920.6, e: 0.027, savings: 2202, debt: -1788,\n",
      "episode: 720/1001, reward: -4e+11, e: 0.027, savings: 5371, debt: -434,\n",
      "episode: 721/1001, reward: -4e+11, e: 0.027, savings: 5279, debt: -452,\n",
      "episode: 722/1001, reward: 1.22e+03, e: 0.027, savings: 519, debt: -177,\n",
      "episode: 723/1001, reward: 788.8, e: 0.027, savings: 3459, debt: -982,\n",
      "episode: 724/1001, reward: 912.8, e: 0.027, savings: 1790, debt: -1802,\n",
      "episode: 725/1001, reward: 932.6, e: 0.026, savings: 2456, debt: -1764,\n",
      "episode: 726/1001, reward: 877.9, e: 0.026, savings: 3892, debt: -1260,\n",
      "episode: 727/1001, reward: 909.3, e: 0.026, savings: 2280, debt: -1820,\n",
      "episode: 728/1001, reward: 510.5, e: 0.026, savings: 699, debt: -1754,\n",
      "episode: 729/1001, reward: 897.5, e: 0.026, savings: 4464, debt: -1082,\n",
      "episode: 730/1001, reward: 2.082e+03, e: 0.026, savings: 5776, debt: -1440,\n",
      "episode: 731/1001, reward: 1.533e+03, e: 0.026, savings: 4920, debt: -155,\n",
      "episode: 732/1001, reward: 1.817e+03, e: 0.025, savings: 5696, debt: -1240,\n",
      "episode: 733/1001, reward: 1.945e+03, e: 0.025, savings: 3364, debt: -359,\n",
      "episode: 734/1001, reward: 4.387e+03, e: 0.025, savings: 4257, debt: -61,\n",
      "episode: 735/1001, reward: 2.058e+03, e: 0.025, savings: 5700, debt: -1299,\n",
      "episode: 736/1001, reward: 1.954e+03, e: 0.025, savings: 3239, debt: -353,\n",
      "episode: 737/1001, reward: 1.294e+03, e: 0.025, savings: 4177, debt: -478,\n",
      "episode: 738/1001, reward: 1.035e+03, e: 0.025, savings: 4783, debt: -318,\n",
      "episode: 739/1001, reward: 1.181e+03, e: 0.025, savings: 4364, debt: -405,\n",
      "episode: 740/1001, reward: 1.02e+03, e: 0.024, savings: 4570, debt: -449,\n",
      "episode: 741/1001, reward: 651.2, e: 0.024, savings: 2027, debt: -1044,\n",
      "episode: 742/1001, reward: 914.7, e: 0.024, savings: 4760, debt: -453,\n",
      "episode: 743/1001, reward: 780.3, e: 0.024, savings: 3292, debt: -982,\n",
      "episode: 744/1001, reward: 872.6, e: 0.024, savings: 1839, debt: -614,\n",
      "episode: 745/1001, reward: 868.7, e: 0.024, savings: 1859, debt: -615,\n",
      "episode: 746/1001, reward: 1.706e+03, e: 0.024, savings: 5936, debt: -1840,\n",
      "episode: 747/1001, reward: 1.546e+03, e: 0.024, savings: 5772, debt: -1678,\n",
      "episode: 748/1001, reward: 1.352e+03, e: 0.024, savings: 5324, debt: -1550,\n",
      "episode: 749/1001, reward: 2.067e+03, e: 0.023, savings: 504, debt: -52,\n",
      "episode: 750/1001, reward: 782.8, e: 0.023, savings: 3392, debt: -984,\n",
      "episode: 751/1001, reward: 982.9, e: 0.023, savings: 4748, debt: -558,\n",
      "episode: 752/1001, reward: 926.4, e: 0.023, savings: 4569, debt: -534,\n",
      "episode: 753/1001, reward: 781.0, e: 0.023, savings: 3293, debt: -952,\n",
      "episode: 754/1001, reward: 1.524e+03, e: 0.023, savings: 5968, debt: -1920,\n",
      "episode: 755/1001, reward: 840.0, e: 0.023, savings: 2261, debt: -719,\n",
      "episode: 756/1001, reward: 766.7, e: 0.023, savings: 3257, debt: -1009,\n",
      "episode: 757/1001, reward: 1.512e+03, e: 0.022, savings: 5868, debt: -1918,\n",
      "episode: 758/1001, reward: 765.4, e: 0.022, savings: 2887, debt: -939,\n",
      "episode: 759/1001, reward: 834.6, e: 0.022, savings: 2266, debt: -725,\n",
      "episode: 760/1001, reward: 1.728e+03, e: 0.022, savings: 508, debt: -151,\n",
      "episode: 761/1001, reward: 960.3, e: 0.022, savings: 4791, debt: -528,\n",
      "episode: 762/1001, reward: 774.8, e: 0.022, savings: 3282, debt: -993,\n",
      "episode: 763/1001, reward: 797.3, e: 0.022, savings: 3432, debt: -1026,\n",
      "episode: 764/1001, reward: 1.068e+03, e: 0.022, savings: 2975, debt: -961,\n",
      "episode: 765/1001, reward: 878.8, e: 0.022, savings: 3910, debt: -1289,\n",
      "episode: 766/1001, reward: 871.4, e: 0.022, savings: 3885, debt: -1305,\n",
      "episode: 767/1001, reward: 881.1, e: 0.021, savings: 3766, debt: -1292,\n",
      "episode: 768/1001, reward: 867.8, e: 0.021, savings: 3870, debt: -1310,\n",
      "episode: 769/1001, reward: 1.03e+03, e: 0.021, savings: 2883, debt: -979,\n",
      "episode: 770/1001, reward: 1.031e+03, e: 0.021, savings: 2727, debt: -938,\n",
      "episode: 771/1001, reward: 1.044e+03, e: 0.021, savings: 2928, debt: -984,\n",
      "episode: 772/1001, reward: 968.3, e: 0.021, savings: 3194, debt: -1095,\n",
      "episode: 773/1001, reward: 1.037e+03, e: 0.021, savings: 2860, debt: -964,\n",
      "episode: 774/1001, reward: 1.029e+03, e: 0.021, savings: 2971, debt: -1000,\n",
      "episode: 775/1001, reward: 1.042e+03, e: 0.021, savings: 2946, debt: -993,\n",
      "episode: 776/1001, reward: 1.013e+03, e: 0.02, savings: 2859, debt: -1017,\n",
      "episode: 777/1001, reward: 1.019e+03, e: 0.02, savings: 2876, debt: -1004,\n",
      "episode: 778/1001, reward: 998.5, e: 0.02, savings: 2882, debt: -1032,\n",
      "episode: 779/1001, reward: 940.0, e: 0.02, savings: 3317, debt: -1207,\n",
      "episode: 780/1001, reward: 864.2, e: 0.02, savings: 3732, debt: -1341,\n",
      "episode: 781/1001, reward: 1.01e+03, e: 0.02, savings: 2892, debt: -1041,\n",
      "episode: 782/1001, reward: 866.5, e: 0.02, savings: 3619, debt: -1356,\n",
      "episode: 783/1001, reward: 999.8, e: 0.02, savings: 2880, debt: -1060,\n",
      "episode: 784/1001, reward: 987.9, e: 0.02, savings: 2800, debt: -1059,\n",
      "episode: 785/1001, reward: 993.7, e: 0.02, savings: 2832, debt: -1041,\n",
      "episode: 786/1001, reward: 870.5, e: 0.019, savings: 3795, debt: -1355,\n",
      "episode: 787/1001, reward: 986.5, e: 0.019, savings: 2788, debt: -1078,\n",
      "episode: 788/1001, reward: 1.004e+03, e: 0.019, savings: 2839, debt: -1016,\n",
      "episode: 789/1001, reward: 1.013e+03, e: 0.019, savings: 2824, debt: -1021,\n",
      "episode: 790/1001, reward: 989.1, e: 0.019, savings: 2888, debt: -1080,\n",
      "episode: 791/1001, reward: 1.096e+03, e: 0.019, savings: 1651, debt: -599,\n",
      "episode: 792/1001, reward: 979.6, e: 0.019, savings: 2856, debt: -1098,\n",
      "episode: 793/1001, reward: 972.1, e: 0.019, savings: 2755, debt: -1054,\n",
      "episode: 794/1001, reward: 853.6, e: 0.019, savings: 3440, debt: -1418,\n",
      "episode: 795/1001, reward: 969.5, e: 0.019, savings: 2852, debt: -1137,\n",
      "episode: 796/1001, reward: 969.3, e: 0.019, savings: 2864, debt: -1118,\n",
      "episode: 797/1001, reward: 857.8, e: 0.018, savings: 3502, debt: -1410,\n",
      "episode: 798/1001, reward: 857.7, e: 0.018, savings: 3625, debt: -1427,\n",
      "episode: 799/1001, reward: 983.8, e: 0.018, savings: 2856, debt: -1098,\n",
      "episode: 800/1001, reward: 965.5, e: 0.018, savings: 2870, debt: -1146,\n",
      "episode: 801/1001, reward: 972.0, e: 0.018, savings: 2852, debt: -1137,\n",
      "episode: 802/1001, reward: 963.5, e: 0.018, savings: 2784, debt: -1117,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 803/1001, reward: 971.1, e: 0.018, savings: 2832, debt: -1136,\n",
      "episode: 804/1001, reward: 949.5, e: 0.018, savings: 2864, debt: -1193,\n",
      "episode: 805/1001, reward: 966.4, e: 0.018, savings: 2832, debt: -1136,\n",
      "episode: 806/1001, reward: 954.5, e: 0.018, savings: 2796, debt: -1193,\n",
      "episode: 807/1001, reward: 958.7, e: 0.018, savings: 2752, debt: -1135,\n",
      "episode: 808/1001, reward: 959.6, e: 0.017, savings: 2699, debt: -1110,\n",
      "episode: 809/1001, reward: 855.1, e: 0.017, savings: 3430, debt: -1449,\n",
      "episode: 810/1001, reward: 861.8, e: 0.017, savings: 3450, debt: -1470,\n",
      "episode: 811/1001, reward: 949.2, e: 0.017, savings: 2849, debt: -1198,\n",
      "episode: 812/1001, reward: 945.4, e: 0.017, savings: 2743, debt: -1168,\n",
      "episode: 813/1001, reward: 935.7, e: 0.017, savings: 2668, debt: -1173,\n",
      "episode: 814/1001, reward: 931.7, e: 0.017, savings: 2862, debt: -1276,\n",
      "episode: 815/1001, reward: 948.5, e: 0.017, savings: 2834, debt: -1203,\n",
      "episode: 816/1001, reward: 854.3, e: 0.017, savings: 3079, debt: -1453,\n",
      "episode: 817/1001, reward: 940.1, e: 0.017, savings: 2751, debt: -1188,\n",
      "episode: 818/1001, reward: 940.5, e: 0.017, savings: 2483, debt: -1069,\n",
      "episode: 819/1001, reward: 907.2, e: 0.016, savings: 3000, debt: -1343,\n",
      "episode: 820/1001, reward: 863.9, e: 0.016, savings: 3330, debt: -1510,\n",
      "episode: 821/1001, reward: 862.9, e: 0.016, savings: 3345, debt: -1505,\n",
      "episode: 822/1001, reward: 854.9, e: 0.016, savings: 3415, debt: -1454,\n",
      "episode: 823/1001, reward: 935.4, e: 0.016, savings: 2739, debt: -1207,\n",
      "episode: 824/1001, reward: 948.4, e: 0.016, savings: 2784, debt: -1212,\n",
      "episode: 825/1001, reward: 859.9, e: 0.016, savings: 3350, debt: -1511,\n",
      "episode: 826/1001, reward: 938.9, e: 0.016, savings: 2556, debt: -1095,\n",
      "episode: 827/1001, reward: 938.2, e: 0.016, savings: 2660, debt: -1153,\n",
      "episode: 828/1001, reward: 929.7, e: 0.016, savings: 2768, debt: -1270,\n",
      "episode: 829/1001, reward: 864.5, e: 0.016, savings: 3270, debt: -1530,\n",
      "episode: 830/1001, reward: 867.5, e: 0.016, savings: 2862, debt: -1418,\n",
      "episode: 831/1001, reward: 873.9, e: 0.016, savings: 3266, debt: -1494,\n",
      "episode: 832/1001, reward: 920.5, e: 0.015, savings: 2635, debt: -1244,\n",
      "episode: 833/1001, reward: 927.9, e: 0.015, savings: 2774, debt: -1298,\n",
      "episode: 834/1001, reward: 862.7, e: 0.015, savings: 3290, debt: -1531,\n",
      "episode: 835/1001, reward: 856.4, e: 0.015, savings: 3322, debt: -1470,\n",
      "episode: 836/1001, reward: 934.4, e: 0.015, savings: 2739, debt: -1207,\n",
      "episode: 837/1001, reward: 928.2, e: 0.015, savings: 2756, debt: -1289,\n",
      "episode: 838/1001, reward: 915.1, e: 0.015, savings: 2423, debt: -1164,\n",
      "episode: 839/1001, reward: 870.8, e: 0.015, savings: 3095, debt: -1596,\n",
      "episode: 840/1001, reward: 870.8, e: 0.015, savings: 3165, debt: -1565,\n",
      "episode: 841/1001, reward: 915.8, e: 0.015, savings: 2667, debt: -1321,\n",
      "episode: 842/1001, reward: 929.8, e: 0.015, savings: 2756, debt: -1289,\n",
      "episode: 843/1001, reward: 894.8, e: 0.015, savings: 2821, debt: -1457,\n",
      "episode: 844/1001, reward: 915.2, e: 0.015, savings: 2684, debt: -1403,\n",
      "episode: 845/1001, reward: 934.1, e: 0.014, savings: 2724, debt: -1307,\n",
      "episode: 846/1001, reward: 901.3, e: 0.014, savings: 2803, debt: -1491,\n",
      "episode: 847/1001, reward: 914.6, e: 0.014, savings: 2699, debt: -1398,\n",
      "episode: 848/1001, reward: 862.7, e: 0.014, savings: 3555, debt: -1435,\n",
      "episode: 849/1001, reward: 874.0, e: 0.014, savings: 3810, debt: -1350,\n",
      "episode: 850/1001, reward: 718.2, e: 0.014, savings: 5160, debt: -1156,\n",
      "episode: 851/1001, reward: 877.6, e: 0.014, savings: 3977, debt: -1204,\n",
      "episode: 852/1001, reward: 893.8, e: 0.014, savings: 4145, debt: -1246,\n",
      "episode: 853/1001, reward: 871.0, e: 0.014, savings: 3860, debt: -1341,\n",
      "episode: 854/1001, reward: 866.2, e: 0.014, savings: 3589, debt: -1366,\n",
      "episode: 855/1001, reward: 861.8, e: 0.014, savings: 3605, debt: -1426,\n",
      "episode: 856/1001, reward: 858.2, e: 0.014, savings: 3417, debt: -1446,\n",
      "episode: 857/1001, reward: 858.1, e: 0.014, savings: 3640, debt: -1422,\n",
      "episode: 858/1001, reward: 870.3, e: 0.014, savings: 3687, debt: -1376,\n",
      "episode: 859/1001, reward: 855.3, e: 0.013, savings: 3690, debt: -1307,\n",
      "episode: 860/1001, reward: 939.3, e: 0.013, savings: 2739, debt: -1207,\n",
      "episode: 861/1001, reward: 977.6, e: 0.013, savings: 2687, debt: -1034,\n",
      "episode: 862/1001, reward: 546.4, e: 0.013, savings: 4812, debt: -1921,\n",
      "episode: 863/1001, reward: 766.3, e: 0.013, savings: 3200, debt: -1000,\n",
      "episode: 864/1001, reward: 920.2, e: 0.013, savings: 2708, debt: -1365,\n",
      "episode: 865/1001, reward: 961.9, e: 0.013, savings: 2731, debt: -1092,\n",
      "episode: 866/1001, reward: 921.3, e: 0.013, savings: 2676, debt: -1383,\n",
      "episode: 867/1001, reward: 943.3, e: 0.013, savings: 2772, debt: -1231,\n",
      "episode: 868/1001, reward: 940.5, e: 0.013, savings: 2772, debt: -1231,\n",
      "episode: 869/1001, reward: 822.6, e: 0.013, savings: 3430, debt: -1117,\n",
      "episode: 870/1001, reward: 750.4, e: 0.013, savings: 3110, debt: -1010,\n",
      "episode: 871/1001, reward: 916.9, e: 0.013, savings: 2496, debt: -1668,\n",
      "episode: 872/1001, reward: 938.0, e: 0.013, savings: 2722, debt: -1220,\n",
      "episode: 873/1001, reward: 942.7, e: 0.013, savings: 2736, debt: -1193,\n",
      "episode: 874/1001, reward: 917.2, e: 0.013, savings: 2652, debt: -1421,\n",
      "episode: 875/1001, reward: 765.9, e: 0.012, savings: 3185, debt: -1005,\n",
      "episode: 876/1001, reward: 925.4, e: 0.012, savings: 2700, debt: -1345,\n",
      "episode: 877/1001, reward: 753.9, e: 0.012, savings: 3105, debt: -1004,\n",
      "episode: 878/1001, reward: 745.0, e: 0.012, savings: 3000, debt: -1019,\n",
      "episode: 879/1001, reward: 911.4, e: 0.012, savings: 2563, debt: -1453,\n",
      "episode: 880/1001, reward: 920.0, e: 0.012, savings: 2644, debt: -1306,\n",
      "episode: 881/1001, reward: 927.1, e: 0.012, savings: 2727, debt: -1321,\n",
      "episode: 882/1001, reward: 914.3, e: 0.012, savings: 2636, debt: -1479,\n",
      "episode: 883/1001, reward: 919.5, e: 0.012, savings: 2652, debt: -1421,\n",
      "episode: 884/1001, reward: 912.3, e: 0.012, savings: 2584, debt: -1401,\n",
      "episode: 885/1001, reward: 924.0, e: 0.012, savings: 2420, debt: -1821,\n",
      "episode: 886/1001, reward: 888.9, e: 0.012, savings: 3750, debt: -1370,\n",
      "episode: 887/1001, reward: 879.6, e: 0.012, savings: 3402, debt: -1471,\n",
      "episode: 888/1001, reward: 926.7, e: 0.012, savings: 2362, debt: -1790,\n",
      "episode: 889/1001, reward: 912.8, e: 0.012, savings: 2559, debt: -1587,\n",
      "episode: 890/1001, reward: 901.4, e: 0.012, savings: 2387, debt: -1604,\n",
      "episode: 891/1001, reward: 921.4, e: 0.011, savings: 2455, debt: -1817,\n",
      "episode: 892/1001, reward: 896.8, e: 0.011, savings: 2292, debt: -1608,\n",
      "episode: 893/1001, reward: 882.9, e: 0.011, savings: 2015, debt: -1810,\n",
      "episode: 894/1001, reward: 852.0, e: 0.011, savings: 2063, debt: -1351,\n",
      "episode: 895/1001, reward: 824.2, e: 0.011, savings: 3440, debt: -1315,\n",
      "episode: 896/1001, reward: 897.2, e: 0.011, savings: 2431, debt: -1567,\n",
      "episode: 897/1001, reward: 860.3, e: 0.011, savings: 3175, debt: -1534,\n",
      "episode: 898/1001, reward: 844.6, e: 0.011, savings: 3445, debt: -1424,\n",
      "episode: 899/1001, reward: 911.3, e: 0.011, savings: 2260, debt: -1819,\n",
      "episode: 900/1001, reward: 867.5, e: 0.011, savings: 3522, debt: -1431,\n",
      "episode: 901/1001, reward: 920.9, e: 0.011, savings: 2340, debt: -1820,\n",
      "episode: 902/1001, reward: 894.4, e: 0.011, savings: 2431, debt: -1567,\n",
      "episode: 903/1001, reward: 835.5, e: 0.011, savings: 1640, debt: -1812,\n",
      "episode: 904/1001, reward: 685.0, e: 0.011, savings: 2397, debt: -1039,\n",
      "episode: 905/1001, reward: 770.4, e: 0.011, savings: 2945, debt: -1314,\n",
      "episode: 906/1001, reward: 785.3, e: 0.011, savings: 2911, debt: -1308,\n",
      "episode: 907/1001, reward: 845.7, e: 0.011, savings: 3265, debt: -1484,\n",
      "episode: 908/1001, reward: 862.4, e: 0.011, savings: 3277, debt: -1485,\n",
      "episode: 909/1001, reward: 802.2, e: 0.01, savings: 3135, debt: -1389,\n",
      "episode: 910/1001, reward: 788.6, e: 0.01, savings: 2962, debt: -1341,\n",
      "episode: 911/1001, reward: 680.0, e: 0.01, savings: 5357, debt: -1218,\n",
      "episode: 912/1001, reward: 699.4, e: 0.01, savings: 5205, debt: -1187,\n",
      "episode: 913/1001, reward: 799.4, e: 0.01, savings: 1200, debt: -1805,\n",
      "episode: 914/1001, reward: 778.6, e: 0.01, savings: 3375, debt: -1863,\n",
      "episode: 915/1001, reward: 924.7, e: 0.01, savings: 2450, debt: -1811,\n",
      "episode: 916/1001, reward: 623.8, e: 0.01, savings: 4262, debt: -1885,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 917/1001, reward: 875.5, e: 0.01, savings: 2899, debt: -1506,\n",
      "episode: 918/1001, reward: 819.8, e: 0.01, savings: 3315, debt: -1349,\n",
      "episode: 919/1001, reward: 915.7, e: 0.01, savings: 2699, debt: -1398,\n",
      "episode: 920/1001, reward: 807.6, e: 0.01, savings: 3085, debt: -1398,\n",
      "episode: 921/1001, reward: 909.9, e: 0.01, savings: 2632, debt: -1518,\n",
      "episode: 922/1001, reward: 914.9, e: 0.01, savings: 2532, debt: -1611,\n",
      "episode: 923/1001, reward: 857.7, e: 0.01, savings: 3295, debt: -1494,\n",
      "episode: 924/1001, reward: 912.7, e: 0.01, savings: 2572, debt: -1613,\n",
      "episode: 925/1001, reward: 907.8, e: 0.01, savings: 2500, debt: -1439,\n",
      "episode: 926/1001, reward: 910.7, e: 0.01, savings: 2600, debt: -1536,\n",
      "episode: 927/1001, reward: 914.7, e: 0.01, savings: 2500, debt: -1727,\n",
      "episode: 928/1001, reward: 920.3, e: 0.01, savings: 2508, debt: -1649,\n",
      "episode: 929/1001, reward: 922.4, e: 0.01, savings: 2335, debt: -1814,\n",
      "episode: 930/1001, reward: 922.1, e: 0.01, savings: 2320, debt: -1819,\n",
      "episode: 931/1001, reward: 916.1, e: 0.01, savings: 2571, debt: -1568,\n",
      "episode: 932/1001, reward: 926.4, e: 0.01, savings: 2415, debt: -1815,\n",
      "episode: 933/1001, reward: 914.8, e: 0.01, savings: 2395, debt: -1794,\n",
      "episode: 934/1001, reward: 763.3, e: 0.01, savings: 3197, debt: -986,\n",
      "episode: 935/1001, reward: 804.5, e: 0.01, savings: 3975, debt: -1548,\n",
      "episode: 936/1001, reward: 696.9, e: 0.01, savings: 5327, debt: -1182,\n",
      "episode: 937/1001, reward: 712.5, e: 0.01, savings: 5300, debt: -1160,\n",
      "episode: 938/1001, reward: 927.0, e: 0.01, savings: 2415, debt: -1815,\n",
      "episode: 939/1001, reward: 932.6, e: 0.01, savings: 2439, debt: -1777,\n",
      "episode: 940/1001, reward: 919.9, e: 0.01, savings: 2320, debt: -1819,\n",
      "episode: 941/1001, reward: 731.0, e: 0.01, savings: 5170, debt: -1122,\n",
      "episode: 942/1001, reward: 926.6, e: 0.01, savings: 2400, debt: -1820,\n",
      "episode: 943/1001, reward: 876.6, e: 0.01, savings: 2200, debt: -1243,\n",
      "episode: 944/1001, reward: 927.7, e: 0.01, savings: 2796, debt: -1343,\n",
      "episode: 945/1001, reward: 911.2, e: 0.01, savings: 2547, debt: -1511,\n",
      "episode: 946/1001, reward: 915.0, e: 0.01, savings: 2628, debt: -1459,\n",
      "episode: 947/1001, reward: 772.7, e: 0.01, savings: 3297, debt: -988,\n",
      "episode: 948/1001, reward: 789.6, e: 0.01, savings: 3582, debt: -976,\n",
      "episode: 949/1001, reward: 537.6, e: 0.01, savings: 4640, debt: -1938,\n",
      "episode: 950/1001, reward: 926.6, e: 0.01, savings: 2400, debt: -1820,\n",
      "episode: 951/1001, reward: 735.2, e: 0.01, savings: 5250, debt: -1123,\n",
      "episode: 952/1001, reward: 917.8, e: 0.01, savings: 2320, debt: -1819,\n",
      "episode: 953/1001, reward: 767.7, e: 0.01, savings: 3300, debt: -1002,\n",
      "episode: 954/1001, reward: 752.5, e: 0.01, savings: 3210, debt: -1012,\n",
      "episode: 955/1001, reward: 905.1, e: 0.01, savings: 2512, debt: -1515,\n",
      "episode: 956/1001, reward: 919.0, e: 0.01, savings: 2355, debt: -1815,\n",
      "episode: 957/1001, reward: 908.0, e: 0.01, savings: 2604, debt: -1402,\n",
      "episode: 958/1001, reward: 926.7, e: 0.01, savings: 2752, debt: -1328,\n",
      "episode: 959/1001, reward: 781.0, e: 0.01, savings: 4870, debt: -1021,\n",
      "episode: 960/1001, reward: 925.8, e: 0.01, savings: 2415, debt: -1815,\n",
      "episode: 961/1001, reward: 926.6, e: 0.01, savings: 2400, debt: -1820,\n",
      "episode: 962/1001, reward: 925.8, e: 0.01, savings: 2415, debt: -1815,\n",
      "episode: 963/1001, reward: 915.7, e: 0.01, savings: 2520, debt: -1630,\n",
      "episode: 964/1001, reward: 796.1, e: 0.01, savings: 3675, debt: -980,\n",
      "episode: 965/1001, reward: 783.2, e: 0.01, savings: 3485, debt: -988,\n",
      "episode: 966/1001, reward: 797.8, e: 0.01, savings: 3965, debt: -974,\n",
      "episode: 967/1001, reward: 919.6, e: 0.01, savings: 2652, debt: -1421,\n",
      "episode: 968/1001, reward: 922.6, e: 0.01, savings: 2320, debt: -1819,\n",
      "episode: 969/1001, reward: 918.3, e: 0.01, savings: 2460, debt: -1823,\n",
      "episode: 970/1001, reward: 943.9, e: 0.01, savings: 2748, debt: -1174,\n",
      "episode: 971/1001, reward: 926.6, e: 0.01, savings: 2400, debt: -1820,\n",
      "episode: 972/1001, reward: 925.3, e: 0.01, savings: 2430, debt: -1810,\n",
      "episode: 973/1001, reward: 961.3, e: 0.01, savings: 2796, debt: -1193,\n",
      "episode: 974/1001, reward: 916.3, e: 0.01, savings: 2648, debt: -1365,\n",
      "episode: 975/1001, reward: 953.2, e: 0.01, savings: 2772, debt: -1231,\n",
      "episode: 976/1001, reward: 919.4, e: 0.01, savings: 2443, debt: -1643,\n",
      "episode: 977/1001, reward: 768.1, e: 0.01, savings: 5004, debt: -1020,\n",
      "episode: 978/1001, reward: 993.4, e: 0.01, savings: 2891, debt: -1094,\n",
      "episode: 979/1001, reward: 930.9, e: 0.01, savings: 2700, debt: -1345,\n",
      "episode: 980/1001, reward: 909.1, e: 0.01, savings: 2240, debt: -1818,\n",
      "episode: 981/1001, reward: 751.9, e: 0.01, savings: 720, debt: -1799,\n",
      "episode: 982/1001, reward: 682.2, e: 0.01, savings: 3200, debt: -1944,\n",
      "episode: 983/1001, reward: 560.8, e: 0.01, savings: 4900, debt: -1978,\n",
      "episode: 984/1001, reward: 343.0, e: 0.01, savings: 5900, debt: -1998,\n",
      "episode: 985/1001, reward: 876.1, e: 0.01, savings: 5038, debt: -463,\n",
      "episode: 986/1001, reward: 965.1, e: 0.01, savings: 4116, debt: -354,\n",
      "episode: 987/1001, reward: 902.6, e: 0.01, savings: 5034, debt: -404,\n",
      "episode: 988/1001, reward: 917.9, e: 0.01, savings: 4974, debt: -332,\n",
      "episode: 989/1001, reward: 990.9, e: 0.01, savings: 2818, debt: -1068,\n",
      "episode: 990/1001, reward: 913.8, e: 0.01, savings: 2360, debt: -1821,\n",
      "episode: 991/1001, reward: 753.4, e: 0.01, savings: 1460, debt: -1821,\n",
      "episode: 992/1001, reward: 341.2, e: 0.01, savings: 5900, debt: -1998,\n",
      "episode: 993/1001, reward: 1.118e+03, e: 0.01, savings: 3948, debt: -1582,\n",
      "episode: 994/1001, reward: 900.5, e: 0.01, savings: 2587, debt: -1513,\n",
      "episode: 995/1001, reward: 952.7, e: 0.01, savings: 2796, debt: -1193,\n",
      "episode: 996/1001, reward: 945.0, e: 0.01, savings: 2536, debt: -1094,\n",
      "episode: 997/1001, reward: 966.2, e: 0.01, savings: 1708, debt: -778,\n",
      "episode: 998/1001, reward: 910.5, e: 0.01, savings: 2116, debt: -993,\n",
      "episode: 999/1001, reward: 954.5, e: 0.01, savings: 2232, debt: -937,\n",
      "episode: 1000/1001, reward: 905.7, e: 0.01, savings: 2411, debt: -1183,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = Corona()\n",
    "done = False # episode has not ended\n",
    "for e in range(n_episodes):#each episode in the range we said (2000)\n",
    "    score = 0\n",
    "    state = env.reset()#start eah episode at the begining f the episode\n",
    "    state = state\n",
    "    state = np.reshape(state, [1, state_size])#reshape this states, and transpode them so they can fit align with the neural network\n",
    "    \n",
    "    for time in range(30*6):#set max number of time-steps the eisode can run for,\n",
    "    #max game-time is 5000 time steps\n",
    "        \n",
    "        #env.render() # for now doesn't work\n",
    "        action = agent.act(state) #pass current state, so that it can take some initial action\n",
    "        \n",
    "        \n",
    "        reward, next_state, done = env.step(action)\n",
    "        #after our agent has taken an action\n",
    "        #we can use that action to pass to the environment \n",
    "        #and get our NExT_STATE and our NEXT_REWARD from the environment\n",
    "        #we also get a boolean -> if the game is done or not\n",
    "        #we take that by taking an step forward\n",
    "        \n",
    "        score += reward  #calculate our reward\n",
    "        #if you are not done, we get a penalty.\n",
    "        #penalize poor actions\n",
    "        \n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        #to remember the previous time-step..., all stuff we want to remember\n",
    "        \n",
    "        state = next_state# what state was in the previous iteration\n",
    "        \n",
    "        if time == 179: #if episode ended, lets print how the agent performed\n",
    "            \n",
    "            print('episode: {}/{}, reward: {:.4}, e: {:.2}, savings: {}, debt: {},'.format(e, n_episodes, score, agent.epsilon, env.x, env.y))\n",
    "            #epsilon, good place to look if the agent is performing well \n",
    "            env.end_frame()\n",
    "            \n",
    "            break\n",
    "        \n",
    "            \n",
    "        #train our data\n",
    "        #give time to the agent to update his weights, so he can improves for future iterations\n",
    "    if len(agent.memory) > batch_size:\n",
    "        agent.replay(batch_size)\n",
    "        \n",
    "    if e% 50 == 0:\n",
    "        agent.save(output_dir + 'weights' + '{:04d}'.format(e) + '.hdf5')#we specify format to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dqn(n_episodes, state_size, action_size):\n",
    "\n",
    "    loss = []\n",
    "    \n",
    "    agent = DQNAgent(state_size, action_size) #initialize our agent\n",
    "    \n",
    "    env = Corona()\n",
    "    done = False # episode has not ended\n",
    "    for e in range(n_episodes):#each episode in the range we said (2000)\n",
    "\n",
    "        state = env.reset()#start eah episode at the begining f the episode\n",
    "        state = state\n",
    "        state = np.reshape(state, [1, state_size])#reshape this states, and transpode them so they can fit align with the neural network\n",
    "\n",
    "        for time in range(5000):#set max number of time-steps the eisode can run for,\n",
    "        #max game-time is 5000 time steps\n",
    "\n",
    "            #env.render() # for now doesn't work\n",
    "            action = agent.act(state) #pass current state, so that it can take some initial action\n",
    "\n",
    "\n",
    "            reward, next_state, done = env.step(action)\n",
    "            #after our agent has taken an action\n",
    "            #we can use that action to pass to the environment \n",
    "            #and get our NExT_STATE and our NEXT_REWARD from the environment\n",
    "            #we also get a boolean -> if the game is done or not\n",
    "            #we take that by taking an step forward\n",
    "\n",
    "            reward = reward if not done else -0.1#calculate our reward\n",
    "            #if you are not done, we get a penalty.\n",
    "            #penalize poor actions\n",
    "\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            #to remember the previous time-step..., all stuff we want to remember\n",
    "\n",
    "            state = next_state# what state was in the previous iteration\n",
    "\n",
    "            if done: #if episode ended, lets print how the agent performed\n",
    "                \n",
    "                \n",
    "                print('episode: {}/{}, score: {}, e: {:.2}'.format(e, n_episodes, time, agent.epsilon))\n",
    "                #epsilon, good place to look if the agent is performing well\n",
    "                break\n",
    "\n",
    "            #train our data\n",
    "            #give time to the agent to update his weights, so he can improves for future iterations\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "\n",
    "        if e% 50 == 0:\n",
    "            agent.save(output_dir + 'weights' + '{:04d}'.format(e) + '.hdf5')#we specify format to print\n",
    "            ------\n",
    "    \n",
    "        loss.append(reward)\n",
    "    return loss\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    ep = 1001\n",
    "    loss = train_dqn(ep,  state_size, action_size)\n",
    "    plt.plot([i for i in range(ep)], loss)\n",
    "    plt.xlabel('episodes')\n",
    "    plt.ylabel('reward')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for time in range(30*6):#set max number of time-steps the eisode can run for,\n",
    "\n",
    "            print(time)\n",
    "            \n",
    "    #if time = 30: #if episode ended, lets print how the agent performed\n",
    "            \n",
    "       # print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "1.6666666666666667\n",
      "1.3333333333333333\n",
      "1.0\n",
      "0.6666666666666666\n",
      "0.3333333333333333\n",
      "0.16666666666666666\n",
      "0.06666666666666667\n",
      "0.03333333333333333\n"
     ]
    }
   ],
   "source": [
    "spending =(6000,5000, 4000, 3000, 2000, 1000, 500, 200, 100)\n",
    "for i in spending:\n",
    "    print(2*(i/6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0526315789473684\n",
      "1.1111111111111112\n",
      "2.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "spending =(-2000,-1900, -1800, -1000, -500)\n",
    "for i in spending:\n",
    "    print((-2000/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
